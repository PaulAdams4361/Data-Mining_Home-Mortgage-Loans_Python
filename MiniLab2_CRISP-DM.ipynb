{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel Schwan, Stuart Miller, Justin Howard, Paul Adams\n",
    "# Lab Two: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniLab2 Project Requirments -\n",
    "1. [Data Preparation](#DataPreparation)\n",
    "    1. [Define and prepare your class variables](#Define)\n",
    "    2. [Describe the final dataset that is used for classification/regression (include a\n",
    "description of any newly formed variables you created](#FinalDataset)\n",
    "\n",
    "\n",
    "2. [Modeling and Evaluation](#DataUnderstanding)\n",
    "    1. [Choose and explain your evaluation metrics that you will use](#Evaluaation)\n",
    "    2. [Choose the method you will use for dividing your data into training and\n",
    "testing splits](#DivideData)\n",
    "    3. [Create three different classification/regression models](#Models)\n",
    "    4. [Analyze the results using your chosen method of evaluation](#Analyze)\n",
    "    5. [Discuss the advantages of each model for each classification task](#Advantages)\n",
    "    6. [Which attributes from your analysis are most important](#Attributes)\n",
    "    \n",
    "    \n",
    "3. [Deployment](#Deployment)\n",
    "    1. [How useful is your model for interested parties (i.e., the companies or\n",
    "organizations that might want to use it for prediction)? How would you measure the\n",
    "model's value if it was used by these parties? How would your deploy your model for\n",
    "interested parties? What other data should be collected? How often would the model\n",
    "need to be updated, etc.?](#Value)\n",
    "\n",
    "A1. [Disclaimer](#Disclaimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./crisps-dm2.png\" style=\"width:550px;height:450px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Stage Three - Data Preperation (Q1)   <a class=\"anchor\" id=\"DataPreparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Define and prepare your class variables (Q1A)<a class=\"anchor\" id=\"Define\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Import Libraries Required.\n",
    "# pydata stack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "#plotting library\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    " # enabling sklearn's experimental gradient boosting machine algorithm\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
    "\n",
    "# others\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from plot_decision_regions import plot_decision_regions\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# custom functions\n",
    "from cleaning import (read_clean_data, impute_data, merge_bureau, merge_previous_application,\n",
    "merge_POS_CASH, merge_credit_card_balance, merge_installments, downsampling_strategy, reduce_mem_usage)\n",
    "from tables import classification_report\n",
    "\n",
    "# set random seed\n",
    "random_state= 1\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data that was preprocessed using the custom read_clean_data() function, \n",
    "# merged with the previously engineered newFeatures from Lab 1 \n",
    "data = read_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape application and bureau data combined: (307511, 115)\n",
      "Dimensions after adding new features:  (307511, 119)\n",
      "Dimensions after adding previous_application:  (307511, 282)\n",
      "Dimensions after adding POS_CASH_balance:  (307511, 296)\n",
      "Dimensions after adding installments:  (307511, 302)\n",
      "Dimensions after adding credit_card_balance:  (307511, 329)\n"
     ]
    }
   ],
   "source": [
    "data_bureau = merge_bureau(data)\n",
    "data_prev = merge_previous_application(data_bureau)\n",
    "data_POS_CASH = merge_POS_CASH(data_prev)\n",
    "data_installments = merge_installments(data_POS_CASH)\n",
    "data_full = merge_credit_card_balance(data_installments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 735.51 MB\n",
      "Memory usage after optimization is: 202.06 MB\n",
      "Decreased by 72.5%\n"
     ]
    }
   ],
   "source": [
    "data_lite = reduce_mem_usage(data_full)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Reducing the Amount of Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  9.,  7.,  8., 10., 13., 14., 12.,\n",
       "       20., 15., 16., 11.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.CNT_FAM_MEMBERS.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains features, such as the number of children an applicant has, where the number of unique values are relatively high, but the percentage of the total makeup is almost imperceptable. The distributions of these high cardinality variables are heavily skewed. To address this issue, the number of numeric categories was reduced to get a more accurate interpretation of their impact on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoding high cardinality features\n",
    "\n",
    "# reducing the child count feature to 3 categories\n",
    "def cnt_child(series):\n",
    "    if series == 0 :\n",
    "        return 'No Children'\n",
    "    elif 1 <= series < 5 :\n",
    "        return '1-4 Children'\n",
    "    else :\n",
    "        return '5 or More Children'\n",
    "data['cnt_child'] = data.CNT_CHILDREN.apply(cnt_child).astype('category')\n",
    "\n",
    "# reducing family count feature to 4 categories\n",
    "def cnt_family(series):\n",
    "    if series == 1:\n",
    "        return '1 Family Member'\n",
    "    elif series == 2: \n",
    "        return '2 Family Members'\n",
    "    elif 3 >= series <= 5:\n",
    "        return '3 - -5 Family Members'\n",
    "    else :\n",
    "        return '6 or more Family Members'\n",
    "data['cnt_family'] = data.CNT_FAM_MEMBERS.apply(cnt_family).astype('category')\n",
    "\n",
    "# reducing engineered feature CREDIT_ACTIVE to 4 categories\n",
    "data.CREDIT_ACTIVE = data.CREDIT_ACTIVE.astype(np.uint32)\n",
    "\n",
    "def credit_active(series):\n",
    "    if series == 0:\n",
    "        return 'No Accounts'\n",
    "    elif 1 <= series <= 3:\n",
    "        return '1-3 Accounts'\n",
    "    else : \n",
    "        return ' > 4 Accounts'\n",
    "data['credit_active'] = data.CREDIT_ACTIVE.apply(credit_active).astype('category')\n",
    "\n",
    "# reducing engineered feature LOAN_COUNT to 5 categories\n",
    "\n",
    "def loan_count(series):\n",
    "    if series == 0:\n",
    "        return 'No Loans'\n",
    "    elif 1 <= series <= 2:\n",
    "        return '1-2 Loans'\n",
    "    elif 3 <= series <= 5:\n",
    "        return '3-5 Loans'\n",
    "    elif 6 <= series <= 10:\n",
    "        return '6-10 Loans'\n",
    "    else : \n",
    "        return ' > 10 Loans'\n",
    "\n",
    "data['loan_cnt'] = data.LOAN_COUNT.apply(loan_count).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Principal Component Analysis\n",
    "\n",
    "Our feature selection decisions prompted a review of the Principal Components to see if a more significant separation between the classes is evident. We dropped variables that seemed the least useful for this type of analysis. Next, we on-hot encoded to eliminate the duplication of categorical features that were already binary indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping variables that were deemed the least useful for analysis\n",
    "new_df = data_lite.copy().drop(['TARGET', 'SK_ID_CURR', 'AMT_GOODS_PRICE'], axis = 1)\n",
    "# one-hot encoding\n",
    "# adding drop_first = True eliminates the duplication of categorical features that are already binary indicators\n",
    "new_df = pd.get_dummies(new_df, drop_first = True)\n",
    "pd.options.display.max_columns = 400\n",
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(new_df)\n",
    "X_train_std = sc.transform(new_df) \n",
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the least useful variables and preforming a one-hot encoding, the resulting data set had an increase in the features from 92 to 192."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov(X_train_std.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "print('\\nTop Ten Eigenvalues \\n%s' % eigen_vals[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total var explained and cumulative variance\n",
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i/tot) for i in sorted(eigen_vals, reverse =True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "len(var_exp)\n",
    "len(cum_var_exp)\n",
    "print(\"Variance Explained length: \" + str(len(var_exp)), \"\\nCumulative Variance Explained length : \" + str(len(cum_var_exp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1,193), var_exp, alpha = .5, align = 'center', label = 'Individual Explained Variance')\n",
    "\n",
    "plt.step(range(1,193), cum_var_exp, where = 'mid', label = 'Cumulative Variance Explained')\n",
    "\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xlabel('Principal Componenet Index')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significant Findings**\n",
    "\n",
    "To capture at least 80% of the variability in the dataset, we must include around 125 principal components. While this is a large number of features, our previous dataset contained 302 features. Our efforts to reduce the cardinality of several features were effective. \n",
    "\n",
    "We will pair the eigenvectors with their corresponding eigenvalues and project them onto a 2-dimensional subspace and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a listof (eigenvalues, eigenvector) tuples\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:,i]) for i in range(len(eigen_vals))]\n",
    "\n",
    "#sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "\"\"\"eigen_pairs[0] is equivalent to the single eigenvalue for PC1 and the eigenvector that represents the 190 features of the data\"\"\"\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse = True)\n",
    "\n",
    "#collecting the two eigenvectors that correspond to the two largest eigenvalues\n",
    "\n",
    "W = np.hstack((eigen_pairs[0][1][:,np.newaxis],\n",
    "               eigen_pairs[1][1][:,np.newaxis]))\n",
    "\n",
    "# printing the first 5 pairs\n",
    "print('Matrix W: \\n', W[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this matrix to transform the training set into new features and plot them. First, we will observe the first 2 Principal Components with a logistic regression-based decision boundary to view the discriminatory ability of a logistic model using the Principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming training data\n",
    "X_train_pca = X_train_std.dot(W)\n",
    "\n",
    "# identifying labels\n",
    "y_train = data.TARGET\n",
    "\n",
    "#initializing the PCA transformer and logistic regression estimator:\n",
    "pca = PCA(n_components =2)\n",
    "lr = LogisticRegression(multi_class = 'ovr',\n",
    "                        random_state = 1,\n",
    "                        solver = 'lbfgs')\n",
    "# dimensionality reduction:\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "#fitting the logitistic regression model on the reduced dataset:\n",
    "lr.fit(X_train_pca, y_train)\n",
    "plot_decision_regions(X_train_pca, y_train, classifier = lr)\n",
    "plt.title('Logistic Regression: Decision Boundary')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend(loc = 'lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significant Findings**\n",
    "\n",
    "From this plot, we can see that class separation is very poor and non-linear. We have two centroids where each has only a slight concentric-ellipse type of separation between the two classes. The decision boundary drawn by a logistic model is clearly unable to use the first two principal components to discriminate between defaults and non-defaulted loans.\n",
    "\n",
    "\n",
    "We can also attempt to view the value of the third principal component to see if there is good separation when we add a third dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting three principal components\n",
    "W3 = np.hstack((W,eigen_pairs[2][1][:,np.newaxis]))\n",
    "W3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming training data\n",
    "X_train_pca3 = X_train_std.dot(W3)\n",
    "X_train_pca3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "\n",
    "colors = ['r','g']\n",
    "markers = ['o', 'x']\n",
    "\n",
    "# for each index and class in:\n",
    "for idx, cl in enumerate(np.unique(y_train)):\n",
    "    ax.scatter3D(X_train_pca3[y_train == cl, 0],\n",
    "                X_train_pca3[y_train == cl, 1],\n",
    "                X_train_pca3[y_train == cl, 2],\n",
    "                label = cl,\n",
    "                s=500,\n",
    "                c = X_train_pca3[y_train == cl, 2],\n",
    "                cmap = 'viridis',\n",
    "                marker = markers[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significant Findings**\n",
    "\n",
    "A three dimensional plot of the data does provide some insights. Defaults can be separated along the third dimension, as indicated by the defaults being clustered in the blue region and the non-defaults being clustered in the green/yellow regions of the third Principal Component.\n",
    "\n",
    "1. The overlap between the classes is so signficant even in the third dimension, that the boundary line is not clear.\n",
    "\n",
    "2. We will apply sampling strategies that will clarify the class boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2 Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). (Q1b) <a class=\"anchor\" id=\"FinalDataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF Feature Removal / Dimensionality Reduction <a class=\"anchor\" id=\"VIF\"></a>\n",
    "\n",
    "High VIF is an [indication of multicollinearity](https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html).\n",
    "Typically, limiting VIF of individual features to 5 is considered reasonable.\n",
    "For removal by VIF, features with high VIF were removed iteratively until the VIF for all remain features was less than 5.\n",
    "The removed features are printed by the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresh=5.0):\n",
    "        \"\"\"Iteratively calculate VIF and drop features with highest VIF until\n",
    "        all VIF values are below the threshold value (`thresh`).\n",
    "        \n",
    "        Adapted from https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class\n",
    "        \"\"\"\n",
    "        # From looking at documentation, values between 5 and 10 are \"okay\".\n",
    "        # Above 10 is too high and so should be removed.\n",
    "        self.thresh = thresh\n",
    "        \n",
    "        # The statsmodel function will fail with NaN values, as such we have to impute them.\n",
    "        # By default we impute using the median value.\n",
    "        # This imputation could be taken out and added as part of an sklearn Pipeline.\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print('ReduceVIF fit')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print('ReduceVIF transform')\n",
    "        columns = X.columns.tolist()\n",
    "        return ReduceVIF.calculate_vif(X, self.thresh)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_vif(X, thresh):\n",
    "        # Taken from https://stats.stackexchange.com/a/253620/53565 and modified\n",
    "        dropped=True\n",
    "        while dropped:\n",
    "            variables = X.columns\n",
    "            dropped = False\n",
    "            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n",
    "            \n",
    "            max_vif = max(vif)\n",
    "            if max_vif > thresh:\n",
    "                maxloc = vif.index(max_vif)\n",
    "                print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n",
    "                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n",
    "                dropped=True\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Feature Selection <a class=\"anchor\" id=\"FeatureSelection\"></a>\n",
    "\n",
    "Feature selection was performed by removing features with high variance inflation factor (VIF) and ranking features by feature importance  with an ensemble of models (regularized logistic regression).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReduceVIF fit\n",
      "ReduceVIF transform\n",
      "Dropping FLAG_EMP_PHONE with vif=inf\n",
      "Dropping OBS_60_CNT_SOCIAL_CIRCLE with vif=305.3561309024784\n",
      "Dropping DAYS_EMPLOYED with vif=26.563116707417766\n",
      "Dropping CREDIT_INCOME_RATIO with vif=12.802783700440655\n",
      "Dropping FLAG_DOCUMENT_3 with vif=12.359954352518328\n",
      "Dropping REGION_RATING_CLIENT with vif=11.328873613921926\n",
      "Dropping REG_REGION_NOT_WORK_REGION with vif=8.86833737152621\n",
      "Dropping REG_CITY_NOT_WORK_CITY with vif=6.576086450010426\n"
     ]
    }
   ],
   "source": [
    "transformer = ReduceVIF()\n",
    "X = transformer.fit_transform(X_train_svm_as_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combined multiple stratification and sampling techniques to the data before training the model:\n",
    "\n",
    "1. Imputations are calculated based on the training set and applied to the test set.\n",
    "2. A stratefied training/test set by `TARGET` : to guarantee similar distributions\n",
    "3. Random-undersampling by the engineered categorical `CAT_INCOME` : clarify the boundaries between income strata\n",
    "4. Tomek Link under-sampling by `TARGET` : clarify the boundaries between `TARGET` classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Stratified Sampling by Incomes\n",
    "Our first step is to separate the `AMT_INCOME_TOTAL` feature and create a new feature by dividing incomes into quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[$147,150 - $202,500, $202,500 - $117,000,000, $25,659 - $112,500, $112,500 - $147,150, $112,500 - $147,150, ..., $147,150 - $202,500, $25,659 - $112,500, $147,150 - $202,500, $147,150 - $202,500, $147,150 - $202,500]\n",
       "Length: 307511\n",
       "Categories (4, object): [$25,659 - $112,500 < $112,500 - $147,150 < $147,150 - $202,500 < $202,500 - $117,000,000]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create quantiles with simple category names based on the quantile ranges\n",
    "\n",
    "income_labels = ['$25,659 - $112,500', '$112,500 - $147,150',\n",
    "                 '$147,150 - $202,500','$202,500 - $117,000,000']\n",
    "\n",
    "CAT_INCOME = pd.qcut(data['AMT_INCOME_TOTAL'], q = 4,\n",
    "                    labels = income_labels)\n",
    "\n",
    "CAT_INCOME.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CAT_INCOME</th>\n",
       "      <th>$25,659 - $112,500</th>\n",
       "      <th>$112,500 - $147,150</th>\n",
       "      <th>$147,150 - $202,500</th>\n",
       "      <th>$202,500 - $117,000,000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.327071</td>\n",
       "      <td>0.172943</td>\n",
       "      <td>0.267350</td>\n",
       "      <td>0.232636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.469144</td>\n",
       "      <td>0.378199</td>\n",
       "      <td>0.442577</td>\n",
       "      <td>0.422513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "CAT_INCOME  $25,659 - $112,500  $112,500 - $147,150  $147,150 - $202,500  \\\n",
       "count            307511.000000        307511.000000        307511.000000   \n",
       "mean                  0.327071             0.172943             0.267350   \n",
       "std                   0.469144             0.378199             0.442577   \n",
       "min                   0.000000             0.000000             0.000000   \n",
       "25%                   0.000000             0.000000             0.000000   \n",
       "50%                   0.000000             0.000000             0.000000   \n",
       "75%                   1.000000             0.000000             1.000000   \n",
       "max                   1.000000             1.000000             1.000000   \n",
       "\n",
       "CAT_INCOME  $202,500 - $117,000,000  \n",
       "count                 307511.000000  \n",
       "mean                       0.232636  \n",
       "std                        0.422513  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.000000  \n",
       "75%                        0.000000  \n",
       "max                        1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simplifying category names\n",
    "data['CAT_INCOME'] = CAT_INCOME.astype('category')\n",
    "#use the get_dummies function to quickly find the percentage of the dataset that each quantile makes up\n",
    "pd.get_dummies(data.CAT_INCOME).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the Data**\n",
    "\n",
    "Now that we have the `CAT_INCOME` feature, we can gather the features we want to include in our model and form strata. \n",
    "\n",
    "Before we perform any sampling techniques, we must split our data into training and test sets. Our training set will consist of approximately 80% of the data, while the test set will be set aside for validation.\n",
    "Imputation is only calculated based on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data without imputions that are distribution dependent\n",
    "data = read_clean_data(preimpute = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming new dataset with target included. We will still drop features that we already decided were not useful.\n",
    "strat_inc = data.copy().drop(labels = ['SK_ID_CURR','AMT_GOODS_PRICE', 'CNT_CHILDREN',\n",
    "                          'CNT_FAM_MEMBERS', 'EXT_SOURCE_1_AV','EXT_SOURCE_2_AV', 'EXT_SOURCE_3_AV'], axis = 1)\n",
    "#print(list(strat_inc.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create our income strata, we will stratefy the training and test data by the `TARGET` variable to assure that class labels in both the training and test sets a distributed the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train count: 246008\n",
      "y_test count: 61503\n",
      "Total: 307511\n"
     ]
    }
   ],
   "source": [
    "# stratify the training and test sets by the target first\n",
    "# must keep TARGET in the training sets at this point to under sample by income\n",
    "y = strat_inc.TARGET\n",
    "X = strat_inc\n",
    "# setting random_state\n",
    "random_state = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = random_state, stratify = y)\n",
    "print('y_train count: ' + str(y_train.count()) + '\\ny_test count: ' + str(y_test.count()) +\n",
    "      '\\nTotal: ' + str(y_train.count() + y_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation**\n",
    "\n",
    "The function `impute_data` calculates imputations values for the following values and applies these values to test set.\n",
    "For categorical variables imputation of the mode was used.\n",
    "For continuous variables imputation of the median was used.\n",
    "\n",
    "| Variable | Imputation Method |\n",
    "|----------|-------------------|\n",
    "| CODE_GENDER | Mode |\n",
    "| NAME_TYPE_SUITE | Mode |\n",
    "| OBS_30_CNT_SOCIAL_CIRCLE | Median |\n",
    "| DEF_30_CNT_SOCIAL_CIRCLE | Median |\n",
    "| OBS_60_CNT_SOCIAL_CIRCLE | Median |\n",
    "| DEF_60_CNT_SOCIAL_CIRCLE | Median |\n",
    "| AMT_ANNUITY |  Median |\n",
    "| ANNUITY_INCOME_RATIO |  Median |\n",
    "| DAYS_LAST_PHONE_CHANGE |  Median |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = impute_data(X_train, X_test)\n",
    "\n",
    "# apply income splits\n",
    "X_train.CAT_INCOME = pd.qcut(X_train['AMT_INCOME_TOTAL'], q = 4,\n",
    "                             labels = income_labels)\n",
    "X_test.CAT_INCOME = pd.qcut(X_test['AMT_INCOME_TOTAL'], q = 4,\n",
    "                             labels = income_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the imputated test and train for analysis of the SVM\n",
    "data_imputed = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Income Strata**\n",
    "\n",
    "We will now take the training set and under-sample all the income categories except the majority category so that it is represented better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207915, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are deciding to under sample all strata except the majority class\n",
    "rus = RandomUnderSampler(random_state = random_state,\n",
    "                         sampling_strategy = 'not majority')\n",
    "\n",
    "# we are undersampling based on strata defined by the CAT_INCOME variable\n",
    "y_inc = X_train.CAT_INCOME\n",
    "X_rus, y_rus = rus.fit_resample(X_train,y_inc)\n",
    "X_rus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have applied an under-sampling strategy to make the majority income class more easily seperable, we can now under-sample by the `TARGET` feature to further clarify the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training set: (207915, 176)\n",
      "Shape of Test set: (61503, 176)\n"
     ]
    }
   ],
   "source": [
    "# preparing training data \n",
    "\n",
    "#removing TARGET from training data\n",
    "y_train = X_rus.pop('TARGET')\n",
    "#getting dummy variables\n",
    "X_train = pd.get_dummies(X_rus, drop_first = True)\n",
    "\n",
    "\n",
    "# preparing test data for evaluation\n",
    "y_test = X_test.pop('TARGET')\n",
    "# create SVM test set with out dummies\n",
    "X_test_svm = X_test.copy()\n",
    "# create test set with dummies\n",
    "X_test = pd.get_dummies(X_test, drop_first = True)\n",
    "\n",
    "# define a function to make empty features for missing features\n",
    "cols = list(X_train.columns)\n",
    "def add_missing_dummies(d, cols):\n",
    "    missing_cols = set(cols) - set(d.columns)\n",
    "    for c in missing_cols:\n",
    "        d[c] = 0\n",
    "add_missing_dummies(X_test, cols)\n",
    "\n",
    "print('Shape of Training set: ' + str(X_train.shape) + '\\nShape of Test set: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the X_rus training data, which is randomly under-sampled by income and under-sample it once more according to the TomekLinks to make the boundary between the classes more evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks()\n",
    "X_tl, y_tl = tl.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resampling the Training Data**\n",
    "\n",
    "Initially, the models were trained against training data that contained mostly non-defaulting instances. However, the model's performance on this initial training data was inferior, generally failing to classify any defaulting instances. The remedy to this issue was to resample the training data to balance the number of non-defaulting and defaulting instances. All the defaulting instances were retained, but the non-defaulting instances were randomly downsampled to match the number of non-defaulting instances. Resampled training data improved the performance of the models substantially when validated on the test data. \n",
    "\n",
    "The test data was **not** resampled.\n",
    "\n",
    "Additionally, the categroical variables were label encoded, rather than one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing TARGET from training data\n",
    "y_train_SVM = y_train.copy()\n",
    "#getting dummy variables\n",
    "X_train_SVM = X_rus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to down sample to deal with training computation time\n",
    "# training on whole set takes about 12hr\n",
    "# use about 20% of the training data\n",
    "downsampled = X_train_SVM.copy()\n",
    "downsampled['TARGET'] = y_train_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_encode = ['ORGANIZATION_TYPE','WEEKDAY_APPR_PROCESS_START','OCCUPATION_TYPE',\n",
    "              'NAME_FAMILY_STATUS','NAME_FAMILY_STATUS','NAME_EDUCATION_TYPE','NAME_INCOME_TYPE',\n",
    "              'NAME_HOUSING_TYPE','NAME_CONTRACT_TYPE', 'FLAG_OWN_REALTY', 'FLAG_OWN_CAR']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in cols_encode:\n",
    "    downsampled[col] = le.fit_transform(downsampled[col])\n",
    "    X_test_svm[col] = le.transform(X_test_svm[col])\n",
    "\n",
    "downsampled = downsampled.drop(labels = ['EXT_SOURCE_3','EXT_SOURCE_1','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                                         'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                                         'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "                                         'AMT_REQ_CREDIT_BUREAU_YEAR', 'NAME_TYPE_SUITE'], axis = 1)\n",
    "X_test_svm = X_test_svm.drop(labels = ['EXT_SOURCE_3','EXT_SOURCE_1','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                                         'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                                         'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "                                         'AMT_REQ_CREDIT_BUREAU_YEAR', 'NAME_TYPE_SUITE'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = downsampled.query('TARGET == 1')\n",
    "nominal = downsampled.query('TARGET == 0').sample(n = np.round(0.5 * (defaults.TARGET.size / 0.5)).astype(int),\n",
    "                                                  random_state = random_state)\n",
    "# join dataframes and shuffle\n",
    "downsampled = pd.concat([defaults, nominal]).sample(frac = 1, \n",
    "                                                    random_state = random_state)\n",
    "\n",
    "X_train_svm = downsampled.drop(labels = ['TARGET'], axis = 1)\n",
    "y_train_svm = downsampled.TARGET\n",
    "\n",
    "# transform the data\n",
    "scaler = StandardScaler()\n",
    "X_train_svm = scaler.fit_transform(X_train_svm)\n",
    "X_test_svm = scaler.transform(X_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svm_as_df = pd.DataFrame(X_train_svm, columns=downsampled.drop(labels = ['TARGET'], axis = 1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Describe the final dataset that is used for classification/regression (Q1B)<a class=\"anchor\" id=\"FinalDataset\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression <a class=\"anchor\" id=\"LogsticRegression\"></a>\n",
    "\n",
    "Each type of regularized logistic regression (L1, L2, ElasticNet) was grid search for the bast hyperparameters.\n",
    "Then the regularized logistic regression models were fit with the hyperparameters selected by [grid search]().\n",
    "After the fits, features where ranked by the mean absolute importance from the model fits ([see table](#FI)).\n",
    "\n",
    "**Note**: ElasticNet was not refit because the grid search or elastic net selected 0 for the regularization mixing parameter,\n",
    "  which is just L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_l1 = LogisticRegression(C = 0.046,\n",
    "                                 penalty = 'l1', \n",
    "                                 solver = 'saga', \n",
    "                                 random_state = random_state)\n",
    "logistic_l1.fit(X, y_train_svm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = logistic_l1.coef_\n",
    "pd.set_option('display.max_rows', 500)\n",
    "coefs_df = pd.DataFrame(data=coefs.flatten())\n",
    "feats_df = X.columns\n",
    "feats_df = feats_df.tolist()\n",
    "feats_df = pd.DataFrame(feats_df)\n",
    "df_new_coeffs = pd.concat([feats_df, coefs_df], axis=1).dropna()\n",
    "df_new_coeffs.columns = ['Feature', 'Logistic Weight']\n",
    "final_df_logistic_l1 = df_new_coeffs.sort_values('Logistic Weight')\n",
    "#final_head = final_df_logistic.head(10)\n",
    "#final_tail = final_df_logistic.tail(10)\n",
    "#final_weights = pd.concat([final_head, final_tail], axis=0)\n",
    "#final_weights['Abs Weight'] = np.abs(final_weights['Logistic Weight'])\n",
    "#final_weights.sort_values('Abs Weight', ascending=False)\n",
    "final_df_logistic_l1['Abs Weight'] = np.abs(final_df_logistic_l1['Logistic Weight'])\n",
    "final_df_logistic_l1.sort_values('Abs Weight', ascending=False, inplace = True)\n",
    "#print(final_df_logistic_l1.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_l2 = LogisticRegression(C = 0.001, \n",
    "                                 penalty = 'l2',\n",
    "                                 solver = 'lbfgs', \n",
    "                                 random_state = random_state)\n",
    "logistic_l2.fit(X, y_train_svm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = logistic_l2.coef_\n",
    "pd.set_option('display.max_rows', 500)\n",
    "coefs_df = pd.DataFrame(data=coefs.flatten())\n",
    "feats_df = X.columns\n",
    "feats_df = feats_df.tolist()\n",
    "feats_df = pd.DataFrame(feats_df)\n",
    "df_new_coeffs = pd.concat([feats_df, coefs_df], axis=1).dropna()\n",
    "df_new_coeffs.columns = ['Feature', 'Logistic Weight']\n",
    "final_df_logistic_l2 = df_new_coeffs.sort_values('Logistic Weight')\n",
    "#final_head = final_df_logistic.head(10)\n",
    "#final_tail = final_df_logistic.tail(10)\n",
    "#final_weights = pd.concat([final_head, final_tail], axis=0)\n",
    "#final_weights['Abs Weight'] = np.abs(final_weights['Logistic Weight'])\n",
    "#final_weights.sort_values('Abs Weight', ascending=False)\n",
    "final_df_logistic_l2['Abs Weight'] = np.abs(final_df_logistic_l2['Logistic Weight'])\n",
    "final_df_logistic_l2.sort_values('Abs Weight', ascending=False, inplace = True)\n",
    "#print(final_df_logistic_l2.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent risk of object corruption\n",
    "l2 = final_df_logistic_l2.sort_values('Feature').copy().add_suffix('_l2')\n",
    "l1 = final_df_logistic_l1.sort_values('Feature').copy().add_suffix('_l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance <a class=\"anchor\" id=\"FI\"></a>\n",
    "\n",
    "The importances were combined for each model and ranked by the mean absolute importance (logstic weight).\n",
    "The weights for each model were also included. \n",
    "The difference and percent difference between the weights for each model is also shown.\n",
    "\n",
    "The difference in feature weight between the two models is not substantial in the first 30 features.\n",
    "There are only a feature features with substantial differences in weights, such as sign changes.\n",
    "All of these features have low importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Abs_Weight</th>\n",
       "      <th>Feature</th>\n",
       "      <th>l1_Weight</th>\n",
       "      <th>l2_Weight</th>\n",
       "      <th>Importance_Difference</th>\n",
       "      <th>Importance_Difference_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438435</td>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>-0.466907</td>\n",
       "      <td>-0.409962</td>\n",
       "      <td>-0.056945</td>\n",
       "      <td>-12.988139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166287</td>\n",
       "      <td>PERCENT_EMPLOYED_TO_AGE</td>\n",
       "      <td>-0.178329</td>\n",
       "      <td>-0.154244</td>\n",
       "      <td>-0.024085</td>\n",
       "      <td>-14.483756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.162195</td>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>-0.172420</td>\n",
       "      <td>-0.151970</td>\n",
       "      <td>-0.020450</td>\n",
       "      <td>-12.608409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141661</td>\n",
       "      <td>DAYS_BIRTH</td>\n",
       "      <td>-0.147777</td>\n",
       "      <td>-0.135544</td>\n",
       "      <td>-0.012233</td>\n",
       "      <td>-8.635488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135792</td>\n",
       "      <td>NAME_EDUCATION_TYPE</td>\n",
       "      <td>0.141790</td>\n",
       "      <td>0.129794</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>8.834419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.130236</td>\n",
       "      <td>NAME_CONTRACT_TYPE</td>\n",
       "      <td>-0.137310</td>\n",
       "      <td>-0.123161</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>-10.864146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.114005</td>\n",
       "      <td>FLAG_OWN_CAR</td>\n",
       "      <td>-0.126493</td>\n",
       "      <td>-0.101516</td>\n",
       "      <td>-0.024977</td>\n",
       "      <td>-21.908926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.098678</td>\n",
       "      <td>DAYS_ID_PUBLISH</td>\n",
       "      <td>-0.101697</td>\n",
       "      <td>-0.095660</td>\n",
       "      <td>-0.006037</td>\n",
       "      <td>-6.117967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.094373</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>0.103532</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.018318</td>\n",
       "      <td>19.410444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.087284</td>\n",
       "      <td>REGION_RATING_CLIENT_W_CITY</td>\n",
       "      <td>0.088142</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>1.965330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.081432</td>\n",
       "      <td>DEF_30_CNT_SOCIAL_CIRCLE</td>\n",
       "      <td>0.094857</td>\n",
       "      <td>0.068008</td>\n",
       "      <td>0.026849</td>\n",
       "      <td>32.970667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.071716</td>\n",
       "      <td>FLAG_WORK_PHONE</td>\n",
       "      <td>0.074399</td>\n",
       "      <td>0.069033</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>7.482311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.069569</td>\n",
       "      <td>DAYS_LAST_PHONE_CHANGE</td>\n",
       "      <td>-0.066452</td>\n",
       "      <td>-0.072685</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>8.959796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.057532</td>\n",
       "      <td>REG_CITY_NOT_LIVE_CITY</td>\n",
       "      <td>0.057391</td>\n",
       "      <td>0.057673</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.491052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.049001</td>\n",
       "      <td>NAME_INCOME_TYPE</td>\n",
       "      <td>0.047684</td>\n",
       "      <td>0.050318</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-5.377030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.045846</td>\n",
       "      <td>FLAG_DOCUMENT_8</td>\n",
       "      <td>-0.048432</td>\n",
       "      <td>-0.043259</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-11.283923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.044904</td>\n",
       "      <td>AMT_CREDIT</td>\n",
       "      <td>-0.046163</td>\n",
       "      <td>-0.043645</td>\n",
       "      <td>-0.002518</td>\n",
       "      <td>-5.608158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.043918</td>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>0.050637</td>\n",
       "      <td>0.037199</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>30.599117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.040006</td>\n",
       "      <td>DAYS_REGISTRATION</td>\n",
       "      <td>-0.038064</td>\n",
       "      <td>-0.041947</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>9.706949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038608</td>\n",
       "      <td>OWN_CAR_AGE</td>\n",
       "      <td>0.045209</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>34.191138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.036968</td>\n",
       "      <td>FLAG_DOCUMENT_13</td>\n",
       "      <td>-0.037318</td>\n",
       "      <td>-0.036618</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-1.895412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.035719</td>\n",
       "      <td>FLAG_DOCUMENT_18</td>\n",
       "      <td>-0.036766</td>\n",
       "      <td>-0.034671</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>-5.863120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.035173</td>\n",
       "      <td>FLAG_DOCUMENT_16</td>\n",
       "      <td>-0.035874</td>\n",
       "      <td>-0.034472</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-3.984814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.034831</td>\n",
       "      <td>FLAG_PHONE</td>\n",
       "      <td>-0.035097</td>\n",
       "      <td>-0.034564</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>-1.528890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.034023</td>\n",
       "      <td>FLAG_DOCUMENT_14</td>\n",
       "      <td>-0.034777</td>\n",
       "      <td>-0.033268</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>-4.436489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.031191</td>\n",
       "      <td>FLAG_DOCUMENT_2</td>\n",
       "      <td>0.033107</td>\n",
       "      <td>0.029276</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>12.281817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.027038</td>\n",
       "      <td>FLAG_DOCUMENT_6</td>\n",
       "      <td>-0.024095</td>\n",
       "      <td>-0.029980</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>21.765378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.023514</td>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "      <td>0.024578</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>9.054351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.022806</td>\n",
       "      <td>FLAG_DOCUMENT_11</td>\n",
       "      <td>-0.023488</td>\n",
       "      <td>-0.022124</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>-5.979910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.021293</td>\n",
       "      <td>FLAG_DOCUMENT_17</td>\n",
       "      <td>-0.021340</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.438686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.021122</td>\n",
       "      <td>LIVE_CITY_NOT_WORK_CITY</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.024653</td>\n",
       "      <td>-0.007063</td>\n",
       "      <td>-33.437042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.020704</td>\n",
       "      <td>NAME_HOUSING_TYPE</td>\n",
       "      <td>0.017580</td>\n",
       "      <td>0.023829</td>\n",
       "      <td>-0.006249</td>\n",
       "      <td>-30.184275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.019576</td>\n",
       "      <td>ANNUITY_INCOME_RATIO</td>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.023875</td>\n",
       "      <td>-0.008598</td>\n",
       "      <td>-43.922952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.017168</td>\n",
       "      <td>FLAG_DOCUMENT_15</td>\n",
       "      <td>-0.016633</td>\n",
       "      <td>-0.017702</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>6.228222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.016721</td>\n",
       "      <td>REG_REGION_NOT_LIVE_REGION</td>\n",
       "      <td>-0.016944</td>\n",
       "      <td>-0.016497</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>-2.672924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.014136</td>\n",
       "      <td>FLAG_DOCUMENT_21</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>-3.857766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.013163</td>\n",
       "      <td>REGION_POPULATION_RELATIVE</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>57.447131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.012707</td>\n",
       "      <td>WEEKDAY_APPR_PROCESS_START</td>\n",
       "      <td>0.012243</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-7.304392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.012434</td>\n",
       "      <td>FLAG_DOCUMENT_20</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-3.320324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.012104</td>\n",
       "      <td>DEF_60_CNT_SOCIAL_CIRCLE</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>-0.023010</td>\n",
       "      <td>-190.103427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.010277</td>\n",
       "      <td>NAME_FAMILY_STATUS</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>-5.292894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.008188</td>\n",
       "      <td>FLAG_CONT_MOBILE</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.008346</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>3.861704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.007910</td>\n",
       "      <td>OBS_30_CNT_SOCIAL_CIRCLE</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>-0.004107</td>\n",
       "      <td>-51.917813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.004692</td>\n",
       "      <td>FLAG_EMAIL</td>\n",
       "      <td>-0.003840</td>\n",
       "      <td>-0.005545</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>36.342967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.004119</td>\n",
       "      <td>FLAG_DOCUMENT_7</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>-36.710067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.004006</td>\n",
       "      <td>FLAG_DOCUMENT_9</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>-0.001772</td>\n",
       "      <td>-44.226759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003964</td>\n",
       "      <td>FLAG_DOCUMENT_5</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>47.875060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.003925</td>\n",
       "      <td>FLAG_DOCUMENT_19</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>50.746164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.002471</td>\n",
       "      <td>FLAG_OWN_REALTY</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-48.321227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.002150</td>\n",
       "      <td>HOUR_APPR_PROCESS_START</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.001131</td>\n",
       "      <td>OCCUPATION_TYPE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002263</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.001099</td>\n",
       "      <td>ORGANIZATION_TYPE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000818</td>\n",
       "      <td>LIVE_REGION_NOT_WORK_REGION</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>-200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>FLAG_DOCUMENT_4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>FLAG_DOCUMENT_12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>FLAG_DOCUMENT_10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>FLAG_MOBIL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean_Abs_Weight                      Feature  l1_Weight  l2_Weight  \\\n",
       "0          0.438435                 EXT_SOURCE_2  -0.466907  -0.409962   \n",
       "1          0.166287      PERCENT_EMPLOYED_TO_AGE  -0.178329  -0.154244   \n",
       "2          0.162195                  CODE_GENDER  -0.172420  -0.151970   \n",
       "3          0.141661                   DAYS_BIRTH  -0.147777  -0.135544   \n",
       "4          0.135792          NAME_EDUCATION_TYPE   0.141790   0.129794   \n",
       "5          0.130236           NAME_CONTRACT_TYPE  -0.137310  -0.123161   \n",
       "6          0.114005                 FLAG_OWN_CAR  -0.126493  -0.101516   \n",
       "7          0.098678              DAYS_ID_PUBLISH  -0.101697  -0.095660   \n",
       "8          0.094373                     EMPLOYED   0.103532   0.085214   \n",
       "9          0.087284  REGION_RATING_CLIENT_W_CITY   0.088142   0.086426   \n",
       "10         0.081432     DEF_30_CNT_SOCIAL_CIRCLE   0.094857   0.068008   \n",
       "11         0.071716              FLAG_WORK_PHONE   0.074399   0.069033   \n",
       "12         0.069569       DAYS_LAST_PHONE_CHANGE  -0.066452  -0.072685   \n",
       "13         0.057532       REG_CITY_NOT_LIVE_CITY   0.057391   0.057673   \n",
       "14         0.049001             NAME_INCOME_TYPE   0.047684   0.050318   \n",
       "15         0.045846              FLAG_DOCUMENT_8  -0.048432  -0.043259   \n",
       "16         0.044904                   AMT_CREDIT  -0.046163  -0.043645   \n",
       "17         0.043918                  AMT_ANNUITY   0.050637   0.037199   \n",
       "18         0.040006            DAYS_REGISTRATION  -0.038064  -0.041947   \n",
       "19         0.038608                  OWN_CAR_AGE   0.045209   0.032008   \n",
       "20         0.036968             FLAG_DOCUMENT_13  -0.037318  -0.036618   \n",
       "21         0.035719             FLAG_DOCUMENT_18  -0.036766  -0.034671   \n",
       "22         0.035173             FLAG_DOCUMENT_16  -0.035874  -0.034472   \n",
       "23         0.034831                   FLAG_PHONE  -0.035097  -0.034564   \n",
       "24         0.034023             FLAG_DOCUMENT_14  -0.034777  -0.033268   \n",
       "25         0.031191              FLAG_DOCUMENT_2   0.033107   0.029276   \n",
       "26         0.027038              FLAG_DOCUMENT_6  -0.024095  -0.029980   \n",
       "27         0.023514             AMT_INCOME_TOTAL   0.024578   0.022449   \n",
       "28         0.022806             FLAG_DOCUMENT_11  -0.023488  -0.022124   \n",
       "29         0.021293             FLAG_DOCUMENT_17  -0.021340  -0.021246   \n",
       "30         0.021122      LIVE_CITY_NOT_WORK_CITY   0.017591   0.024653   \n",
       "31         0.020704            NAME_HOUSING_TYPE   0.017580   0.023829   \n",
       "32         0.019576         ANNUITY_INCOME_RATIO   0.015276   0.023875   \n",
       "33         0.017168             FLAG_DOCUMENT_15  -0.016633  -0.017702   \n",
       "34         0.016721   REG_REGION_NOT_LIVE_REGION  -0.016944  -0.016497   \n",
       "35         0.014136             FLAG_DOCUMENT_21   0.013863   0.014409   \n",
       "36         0.013163   REGION_POPULATION_RELATIVE   0.016943   0.009382   \n",
       "37         0.012707   WEEKDAY_APPR_PROCESS_START   0.012243   0.013172   \n",
       "38         0.012434             FLAG_DOCUMENT_20   0.012228   0.012641   \n",
       "39         0.012104     DEF_60_CNT_SOCIAL_CIRCLE   0.000599   0.023609   \n",
       "40         0.010277           NAME_FAMILY_STATUS   0.010005   0.010549   \n",
       "41         0.008188             FLAG_CONT_MOBILE  -0.008030  -0.008346   \n",
       "42         0.007910     OBS_30_CNT_SOCIAL_CIRCLE   0.005857   0.009963   \n",
       "43         0.004692                   FLAG_EMAIL  -0.003840  -0.005545   \n",
       "44         0.004119              FLAG_DOCUMENT_7   0.003363   0.004875   \n",
       "45         0.004006              FLAG_DOCUMENT_9   0.003120   0.004891   \n",
       "46         0.003964              FLAG_DOCUMENT_5  -0.003015  -0.004913   \n",
       "47         0.003925             FLAG_DOCUMENT_19  -0.002929  -0.004921   \n",
       "48         0.002471              FLAG_OWN_REALTY   0.001874   0.003068   \n",
       "49         0.002150      HOUR_APPR_PROCESS_START   0.000000  -0.004300   \n",
       "50         0.001131              OCCUPATION_TYPE   0.000000  -0.002263   \n",
       "51         0.001099            ORGANIZATION_TYPE   0.000000  -0.002199   \n",
       "52         0.000818  LIVE_REGION_NOT_WORK_REGION   0.000000   0.001637   \n",
       "53         0.000000              FLAG_DOCUMENT_4   0.000000   0.000000   \n",
       "54         0.000000             FLAG_DOCUMENT_12   0.000000   0.000000   \n",
       "55         0.000000             FLAG_DOCUMENT_10   0.000000   0.000000   \n",
       "56         0.000000                   FLAG_MOBIL   0.000000   0.000000   \n",
       "\n",
       "    Importance_Difference  Importance_Difference_%  \n",
       "0               -0.056945               -12.988139  \n",
       "1               -0.024085               -14.483756  \n",
       "2               -0.020450               -12.608409  \n",
       "3               -0.012233                -8.635488  \n",
       "4                0.011996                 8.834419  \n",
       "5               -0.014149               -10.864146  \n",
       "6               -0.024977               -21.908926  \n",
       "7               -0.006037                -6.117967  \n",
       "8                0.018318                19.410444  \n",
       "9                0.001715                 1.965330  \n",
       "10               0.026849                32.970667  \n",
       "11               0.005366                 7.482311  \n",
       "12               0.006233                 8.959796  \n",
       "13              -0.000283                -0.491052  \n",
       "14              -0.002635                -5.377030  \n",
       "15              -0.005173               -11.283923  \n",
       "16              -0.002518                -5.608158  \n",
       "17               0.013438                30.599117  \n",
       "18               0.003883                 9.706949  \n",
       "19               0.013201                34.191138  \n",
       "20              -0.000701                -1.895412  \n",
       "21              -0.002094                -5.863120  \n",
       "22              -0.001402                -3.984814  \n",
       "23              -0.000533                -1.528890  \n",
       "24              -0.001509                -4.436489  \n",
       "25               0.003831                12.281817  \n",
       "26               0.005885                21.765378  \n",
       "27               0.002129                 9.054351  \n",
       "28              -0.001364                -5.979910  \n",
       "29              -0.000093                -0.438686  \n",
       "30              -0.007063               -33.437042  \n",
       "31              -0.006249               -30.184275  \n",
       "32              -0.008598               -43.922952  \n",
       "33               0.001069                 6.228222  \n",
       "34              -0.000447                -2.672924  \n",
       "35              -0.000545                -3.857766  \n",
       "36               0.007562                57.447131  \n",
       "37              -0.000928                -7.304392  \n",
       "38              -0.000413                -3.320324  \n",
       "39              -0.023010              -190.103427  \n",
       "40              -0.000544                -5.292894  \n",
       "41               0.000316                 3.861704  \n",
       "42              -0.004107               -51.917813  \n",
       "43               0.001705                36.342967  \n",
       "44              -0.001512               -36.710067  \n",
       "45              -0.001772               -44.226759  \n",
       "46               0.001898                47.875060  \n",
       "47               0.001992                50.746164  \n",
       "48              -0.001194               -48.321227  \n",
       "49               0.004300               200.000000  \n",
       "50               0.002263               200.000000  \n",
       "51               0.002199               200.000000  \n",
       "52              -0.001637              -200.000000  \n",
       "53               0.000000                      NaN  \n",
       "54               0.000000                      NaN  \n",
       "55               0.000000                      NaN  \n",
       "56               0.000000                      NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.concat([l1, l2], keys=['Feature_l1', 'Feature_l2'], axis = 1)\n",
    "combined['Average Weight'] = (combined['Feature_l1']['Abs Weight_l1'] \n",
    "                              + combined['Feature_l2']['Abs Weight_l2']) / 2\n",
    "average_weights = pd.DataFrame()\n",
    "average_weights['Mean_Abs_Weight'] = combined['Average Weight']\n",
    "average_weights['Feature'] = combined['Feature_l1']['Feature_l1']\n",
    "average_weights['l1_Weight'] = combined['Feature_l1']['Logistic Weight_l1']\n",
    "average_weights['l2_Weight'] = combined['Feature_l2']['Logistic Weight_l2']\n",
    "average_weights['Importance_Difference'] = average_weights['l1_Weight'] - average_weights['l2_Weight']\n",
    "average_weights['Importance_Difference_%'] = (average_weights['Importance_Difference'] \n",
    "                                              / average_weights['Mean_Abs_Weight'] \n",
    "                                              * 100)\n",
    "average_weights = average_weights.sort_values('Mean_Abs_Weight', ascending = False).reset_index(drop = True)\n",
    "average_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit with Important Features <a class=\"anchor\" id=\"Refit\"></a>\n",
    "\n",
    "The L2 regularized logistic model was refit with the 15 most important features (shown below).\n",
    "The produces 64.99% recall and 15.12% precision, which is an improvement over the baseline logistic model (Recall: 63.06%, Precision: 14.36%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    EXT_SOURCE_2\n",
       "1         PERCENT_EMPLOYED_TO_AGE\n",
       "2                     CODE_GENDER\n",
       "3                      DAYS_BIRTH\n",
       "4             NAME_EDUCATION_TYPE\n",
       "5              NAME_CONTRACT_TYPE\n",
       "6                    FLAG_OWN_CAR\n",
       "7                 DAYS_ID_PUBLISH\n",
       "8                        EMPLOYED\n",
       "9     REGION_RATING_CLIENT_W_CITY\n",
       "10       DEF_30_CNT_SOCIAL_CIRCLE\n",
       "11                FLAG_WORK_PHONE\n",
       "12         DAYS_LAST_PHONE_CHANGE\n",
       "13         REG_CITY_NOT_LIVE_CITY\n",
       "14               NAME_INCOME_TYPE\n",
       "Name: Feature, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_weights.iloc[0:15].Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted      0      1    All\n",
      "True                          \n",
      "0          37781  18757  56538\n",
      "1           1857   3108   4965\n",
      "All        39638  21865  61503\n",
      "\n",
      "Accuracy: 66.48% \n",
      "Precision: 14.21% \n",
      "Recall: 62.60%\n"
     ]
    }
   ],
   "source": [
    "l = LogisticRegression(C = 0.001, \n",
    "                         penalty = 'l2',\n",
    "                         solver = 'lbfgs', \n",
    "                         random_state = random_state)\n",
    "l.fit(X[average_weights.iloc[0:15].Feature],y_train_svm)\n",
    "X_test_asdf = pd.DataFrame(X_test_svm, columns=downsampled.drop(labels = ['TARGET'], axis = 1).columns)\n",
    "preds = l.predict(X_test_asdf[average_weights.iloc[0:15].Feature])\n",
    "classification_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and AUC\n",
    "\n",
    "fpr = dict() # false positive rate\n",
    "tpr = dict() # true positive rate\n",
    "roc_auc = dict() # area under the curve\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, l.predict_proba(X_test_asdf[average_weights.iloc[0:15].Feature])[:,1])\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "#plotting\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label= 'Logistic Regression (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Parameter Grid Search <a class=\"anchor\" id=\"GridSearch\"></a>\n",
    "\n",
    "Each type of regularized logistic regression was grid search for the best hyperparameters before fitting the model for estimating feature importances.\n",
    "\n",
    "* L2 Regulaization\n",
    "* L1 Regulaization\n",
    "* Elastic Net Regulaization\n",
    "\n",
    "### L2 Regulaization\n",
    "\n",
    "#### Grid Search Parameters\n",
    "\n",
    "* `C`\n",
    "  * Inverse of the regulaization strength \n",
    "  * (-10, 10) with 100 steps in a log space\n",
    "* `solver`\n",
    "  * Optimization algorithm\n",
    "  * ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ for L2 regularization\n",
    "* `l1_ratio`\n",
    "  * The elastic net mixing ratio\n",
    "  * (0, 1) with 100 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.3593813663804626, 'solver': 'saga'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'newton-cg'}\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'lbfgs'}\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'sag'}\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'saga'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'newton-cg'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'lbfgs'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'sag'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 0.046415888336127774, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 0.046415888336127774, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 0.046415888336127774, 'solver': 'sag'}\n",
      "0.648 (+/-0.008) for {'C': 0.046415888336127774, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 0.3593813663804626, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 0.3593813663804626, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.008) for {'C': 0.3593813663804626, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 0.3593813663804626, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 2.782559402207126, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 2.782559402207126, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.008) for {'C': 2.782559402207126, 'solver': 'sag'}\n",
      "0.648 (+/-0.008) for {'C': 2.782559402207126, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 21.54434690031882, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 21.54434690031882, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.008) for {'C': 21.54434690031882, 'solver': 'sag'}\n",
      "0.648 (+/-0.008) for {'C': 21.54434690031882, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 166.81005372000558, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.008) for {'C': 166.81005372000558, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.008) for {'C': 166.81005372000558, 'solver': 'sag'}\n",
      "0.648 (+/-0.008) for {'C': 166.81005372000558, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 1291.5496650148827, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 1291.5496650148827, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.008) for {'C': 1291.5496650148827, 'solver': 'sag'}\n",
      "0.648 (+/-0.008) for {'C': 1291.5496650148827, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 10000.0, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 10000.0, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.008) for {'C': 10000.0, 'solver': 'sag'}\n",
      "0.648 (+/-0.008) for {'C': 10000.0, 'solver': 'saga'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "Classification Report\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted      0      1    All\n",
      "True                          \n",
      "0          37865  18673  56538\n",
      "1           1837   3128   4965\n",
      "All        39702  21801  61503\n",
      "\n",
      "Accuracy: 66.65% \n",
      "Precision: 14.35% \n",
      "Recall: 63.00%\n",
      "None\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.3593813663804626, 'solver': 'saga'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'newton-cg'}\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'lbfgs'}\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'sag'}\n",
      "0.644 (+/-0.005) for {'C': 0.0001, 'solver': 'saga'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'newton-cg'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'lbfgs'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'sag'}\n",
      "0.647 (+/-0.007) for {'C': 0.000774263682681127, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 0.005994842503189409, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 0.046415888336127774, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 0.046415888336127774, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 0.046415888336127774, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 0.046415888336127774, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 0.3593813663804626, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 0.3593813663804626, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.008) for {'C': 0.3593813663804626, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 0.3593813663804626, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 2.782559402207126, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 2.782559402207126, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 2.782559402207126, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 2.782559402207126, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 21.54434690031882, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 21.54434690031882, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 21.54434690031882, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 21.54434690031882, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 166.81005372000558, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 166.81005372000558, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 166.81005372000558, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 166.81005372000558, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 1291.5496650148827, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 1291.5496650148827, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 1291.5496650148827, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 1291.5496650148827, 'solver': 'saga'}\n",
      "0.648 (+/-0.007) for {'C': 10000.0, 'solver': 'newton-cg'}\n",
      "0.648 (+/-0.007) for {'C': 10000.0, 'solver': 'lbfgs'}\n",
      "0.648 (+/-0.007) for {'C': 10000.0, 'solver': 'sag'}\n",
      "0.648 (+/-0.007) for {'C': 10000.0, 'solver': 'saga'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "Classification Report\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted      0      1    All\n",
      "True                          \n",
      "0          37865  18673  56538\n",
      "1           1837   3128   4965\n",
      "All        39702  21801  61503\n",
      "\n",
      "Accuracy: 66.65% \n",
      "Precision: 14.35% \n",
      "Recall: 63.00%\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = ['precision', 'recall']\n",
    "\n",
    "# Create tuned parameters.\n",
    "tuned_parameters = [\n",
    "    {\n",
    "        'solver':[\n",
    "                     'newton-cg',\n",
    "                     'lbfgs',\n",
    "                     'sag',\n",
    "                     'saga'\n",
    "                 ],\n",
    "        'C':np.logspace(-4, 4, 10)\n",
    "    }]\n",
    "\n",
    "model = LogisticRegression(penalty = 'l2', random_state = random_state)\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        model,\n",
    "        tuned_parameters,\n",
    "        scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_svm)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "# Fit on data\n",
    "#best_clf = clf.fit(X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l1 Regularization\n",
    "\n",
    "#### Grid Search Parameters\n",
    "\n",
    "* `C`\n",
    "  * Inverse of the regulaization strength \n",
    "  * (-10, 10) with 100 steps in a log space\n",
    "* `solver`\n",
    "  * Optimization algorithm\n",
    "  * ‘liblinear’ and ‘saga’ for L1 regularization\n",
    "* `l1_ratio`\n",
    "  * The elastic net mixing ratio\n",
    "  * (0, 1) with 100 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "# Create tuned parameters.\n",
    "tuned_parameters = [\n",
    "    {\n",
    "        'solver':[\n",
    "                     'liblinear',\n",
    "                     'saga'\n",
    "                 ],\n",
    "        'C':np.logspace(-4, 4, 10)\n",
    "    }]\n",
    "\n",
    "model = LogisticRegression(penalty = 'l1', random_state = random_state)\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        model,\n",
    "        tuned_parameters,\n",
    "        scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_svm)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "#### Grid Search Parameters\n",
    "\n",
    "* `C`\n",
    "  * Inverse of the regulaization strength \n",
    "  * (-4, 4) with 10 steps in a log space\n",
    "* `solver`\n",
    "  * Optimization algorithm\n",
    "  * ‘saga’ for elastic-net\n",
    "* `l1_ratio`\n",
    "  * The elastic net mixing ratio\n",
    "  * (0, 1) with 10 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "# Create tuned parameters.\n",
    "tuned_parameters = [\n",
    "    {\n",
    "        'solver':['saga'],\n",
    "        'C':np.logspace(-4, 4, 10),\n",
    "        'l1_ratio':np.linspace(0, 1, 10)\n",
    "    }]\n",
    "\n",
    "model = LogisticRegression(penalty = 'elasticnet', random_state = random_state)\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        model,\n",
    "        tuned_parameters,\n",
    "        scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_svm)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Stage Four - Modeling and Evaluation (Q2) <a class=\"DataUnderstanding\" id=\"EDA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Choose and explain your evaluation metrics (Q2A) <a class=\"anchor\" id=\"Evaluaation\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the significant overlap between the classes in our dataset, we have elected to evaluate our models using the recall metric. Recall is the ratio of accurately predicted defaults to total defaults, which allows us to extract value from the model. \n",
    "\n",
    "We will provide an example of why we deemed this necessary.\n",
    "\n",
    "Below is a Gradient Boosting Machines model that uses the entire dataset to make class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # enabling sklearn's experimental gradient boosting machine algorithm\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    " # now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf = HistGradientBoostingClassifier().fit(X_train_std, y_train)\n",
    "clf.score(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 92% is deceptive. The significant imbalance of the dataset creates this deception. The goal of the analysis is to build a model capable of predicting loan defaults. If we remember that over 90% of the loans in the dataset were in good standing, we can then understand how our model can easily achieve an accuracy of at least 90% by sheer coincidence. \n",
    "\n",
    "We will now observe the recall of the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf, X_train_std, y_train, cv = 5, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall ability of this model ranges from 1.1% to 1.3%. This reveals that the model is useless for predicting loan defaults. \n",
    "\n",
    "We will experiment with various resampling strategies until significant improvements are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Choose the method you will use for dividing your data (Q2B) <a class=\"anchor\" id=\"Describedata\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using an 80/20 training : test set split.\n",
    "\n",
    "As previously mentioned in section 1.2 (Data Description) we concluded that it was necessary to implement a sampling strategy on the training set in order to make a useful model for predicting loan defaults. \n",
    "\n",
    "As a justification of the use of a generic sampling strategy with this dataset, we will provide an example of the effectiveness of simple Randum Under Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X = X_train_std\n",
    "y = data.TARGET\n",
    "rus = RandomUnderSampler(random_state = 1)\n",
    "X_rus, y_rus = rus.fit_resample(X,y)\n",
    "y_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HistGradientBoostingClassifier().fit(X_rus, y_rus)\n",
    "clf.score(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X_rus, y_rus, cv = 5, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying random under-sampling of the majority class permits the gradient boosting algorithm to better define the class differences. Our ability to detect loans that enter default status increased over 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3  Create three different classification/regression models (Q2C) <a class=\"anchor\" id=\"Models\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Analyze the results using your chosen method of evaluation (Q2D) <a class=\"anchor\" id=\"Analyze\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Discuss the advantages of each model for each classification task (Q2E) <a class=\"anchor\" id=\"Advantages\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Which attributes from your analysis are most important (Q2F) <a class=\"anchor\" id=\"Attributes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stage Five - Deployment (Q3) <a class=\"anchor\" id=\"Deployment\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? (Q3A) <a class=\"anchor\" id=\"Value\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1. Disclaimer<a class=\"anchor\" id=\"Disclaimer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer for Home Credit Default Research Paper\n",
    "If you require any more information or have any questions about this papers disclaimer, please feel free to contact us by email at mschwan@smu.edu\n",
    "## Disclaimers for Home Credit Default Research Paper\n",
    "All the information for this research paper is published in good faith and for general information purpose only. Spring 2020 SMU Machine Learning One project team Schwan, Adams, Stewart, and Howard does not make any warranties about the completeness, reliability, and accuracy of this information. Any action you take upon the information you find within this paper is strictly at your own risk. This project team will not be liable for any losses and/or damages in connection with the use of our research analysis paper.\n",
    "From our references, you can visit other websites and papers by following hyperlinks to such external sites. While we strive to provide only quality research references to useful and ethical content, we have no control over the content and nature of these sites. These links to other websites and papers do not imply a recommendation for all the content found within. Please be also aware that when you leave our website, other sites may have different privacy policies and terms which are beyond our control. Please be sure to check the Privacy Policies of these sites as well as their “Terms of Service” before engaging in any business or uploading any information.\n",
    "## Consent\n",
    "By reading our research paper content, you hereby consent to our disclaimer and agree to its terms.\n",
    "## Update\n",
    "Should we update, amend or make any changes to this document, those changes will be prominently posted here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
