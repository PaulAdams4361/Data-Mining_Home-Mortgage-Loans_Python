{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel Schwan, Stuart Miller, Justin Howard, Paul Adams\n",
    "# Lab Two: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniLab2 Project Requirments -\n",
    "1. [Data Preparation](#DataPreparation)\n",
    "    1. [Define and prepare your class variables](#Define)\n",
    "    2. [Describe the final dataset that is used for classification/regression (include a\n",
    "description of any newly formed variables you created](#FinalDataset)\n",
    "\n",
    "\n",
    "2. [Modeling and Evaluation](#DataUnderstanding)\n",
    "    1. [Choose and explain your evaluation metrics that you will use](#Evaluaation)\n",
    "    2. [Choose the method you will use for dividing your data into training and\n",
    "testing splits](#DivideData)\n",
    "    3. [Create three different classification/regression models](#Models)\n",
    "    4. [Analyze the results using your chosen method of evaluation](#Analyze)\n",
    "    5. [Discuss the advantages of each model for each classification task](#Advantages)\n",
    "    6. [Which attributes from your analysis are most important](#Attributes)\n",
    "    \n",
    "    \n",
    "3. [Deployment](#Deployment)\n",
    "    1. [How useful is your model for interested parties (i.e., the companies or\n",
    "organizations that might want to use it for prediction)? How would you measure the\n",
    "model's value if it was used by these parties? How would your deploy your model for\n",
    "interested parties? What other data should be collected? How often would the model\n",
    "need to be updated, etc.?](#Value)\n",
    "\n",
    "A1. [Disclaimer](#Disclaimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./crisps-dm2.png\" style=\"width:550px;height:450px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Stage Three - Data Preperation (Q1)   <a class=\"anchor\" id=\"DataPreparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Define and prepare your class variables (Q1A)<a class=\"anchor\" id=\"Define\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Import Libraries Required.\n",
    "# pydata stack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "#plotting library\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    " # enabling sklearn's experimental gradient boosting machine algorithm\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
    "\n",
    "# others\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from plot_decision_regions import plot_decision_regions\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# custom functions\n",
    "from cleaning import (read_clean_data, impute_data, merge_bureau, merge_previous_application,\n",
    "merge_POS_CASH, merge_credit_card_balance, merge_installments, downsampling_strategy, reduce_mem_usage)\n",
    "from tables import classification_report\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# set random seed\n",
    "random_state= 1\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Loading and Merging the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data that was preprocessed using the custom read_clean_data() function, \n",
    "# merged with the previously engineered newFeatures from Lab 1 \n",
    "data = read_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape application and bureau data combined: (307511, 115)\n",
      "Dimensions after adding new features:  (307511, 119)\n",
      "Dimensions after adding previous_application:  (307511, 282)\n",
      "Dimensions after adding POS_CASH_balance:  (307511, 296)\n",
      "Dimensions after adding installments:  (307511, 302)\n",
      "Dimensions after adding credit_card_balance:  (307511, 329)\n"
     ]
    }
   ],
   "source": [
    "data_bureau = merge_bureau(data)\n",
    "data_prev = merge_previous_application(data_bureau)\n",
    "data_POS_CASH = merge_POS_CASH(data_prev)\n",
    "data_installments = merge_installments(data_POS_CASH)\n",
    "data_full = merge_credit_card_balance(data_installments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307511 entries, 0 to 307510\n",
      "Columns: 329 entries, SK_ID_CURR to CREDIT_NAME_CONTRACT_STATUS_Signed\n",
      "dtypes: float32(2), float64(265), int64(51), uint16(10), uint32(1)\n",
      "memory usage: 753.1 MB\n"
     ]
    }
   ],
   "source": [
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 753.11 MB\n",
      "Memory usage after optimization is: 202.06 MB\n",
      "Decreased by 73.2%\n"
     ]
    }
   ],
   "source": [
    "data_lite = reduce_mem_usage(data_full)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Reducing the Amount of Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  9.,  7.,  8., 10., 13., 14., 12.,\n",
       "       20., 15., 16., 11.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.CNT_FAM_MEMBERS.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains features, such as the number of children an applicant has, where the number of unique values are relatively high, but the percentage of the total makeup is almost imperceptable. The distributions of these high cardinality variables are heavily skewed. To address this issue, the number of numeric categories was reduced to get a more accurate interpretation of their impact on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoding least valuable cateogries into meaningful bins\n",
    "\n",
    "# reducing the child count feature to 3 categories\n",
    "def cnt_child(series):\n",
    "    if series == 0 :\n",
    "        return 'No Children'\n",
    "    elif 1 <= series < 5 :\n",
    "        return '1-4 Children'\n",
    "    else :\n",
    "        return '5 or More Children'\n",
    "\n",
    "# reducing family count feature to 4 categories\n",
    "def cnt_family(series):\n",
    "    if series == 1:\n",
    "        return '1 Family Member'\n",
    "    elif series == 2: \n",
    "        return '2 Family Members'\n",
    "    elif 3 >= series <= 5:\n",
    "        return '3 - -5 Family Members'\n",
    "    else :\n",
    "        return '6 or more Family Members'\n",
    "\n",
    "# reducing engineered feature CREDIT_ACTIVE to 4 categories\n",
    "data.CREDIT_ACTIVE = data.CREDIT_ACTIVE.astype(np.uint32)\n",
    "\n",
    "def credit_active(series):\n",
    "    if series == 0:\n",
    "        return 'No Accounts'\n",
    "    elif 1 <= series <= 3:\n",
    "        return '1-3 Accounts'\n",
    "    else : \n",
    "        return ' > 4 Accounts'\n",
    "\n",
    "# reducing engineered feature LOAN_COUNT to 5 categories\n",
    "\n",
    "def loan_count(series):\n",
    "    if series == 0:\n",
    "        return 'No Loans'\n",
    "    elif 1 <= series <= 2:\n",
    "        return '1-2 Loans'\n",
    "    elif 3 <= series <= 5:\n",
    "        return '3-5 Loans'\n",
    "    elif 6 <= series <= 10:\n",
    "        return '6-10 Loans'\n",
    "    else : \n",
    "        return ' > 10 Loans'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sampling strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combined multiple stratification and sampling techniques to the data before training the model:\n",
    "\n",
    "1. Imputations are calculated based on the training set and applied to the test set.\n",
    "2. A stratefied training/test set by `TARGET` : to guarantee similar distributions\n",
    "3. Random-undersampling by the engineered categorical `CAT_INCOME` : clarify the boundaries between income strata\n",
    "4. Tomek Link under-sampling by `TARGET` : clarify the boundaries between `TARGET` classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Stratified Sampling by Incomes\n",
    "Our first step is to separate the `AMT_INCOME_TOTAL` feature and create a new feature by dividing incomes into quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[$147,150 - $202,500, $202,500 - $117,000,000, $25,659 - $112,500, $112,500 - $147,150, $112,500 - $147,150, ..., $147,150 - $202,500, $25,659 - $112,500, $147,150 - $202,500, $147,150 - $202,500, $147,150 - $202,500]\n",
       "Length: 307511\n",
       "Categories (4, object): [$25,659 - $112,500 < $112,500 - $147,150 < $147,150 - $202,500 < $202,500 - $117,000,000]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create quantiles with simple category names based on the quantile ranges\n",
    "\n",
    "income_labels = ['$25,659 - $112,500', '$112,500 - $147,150',\n",
    "                 '$147,150 - $202,500','$202,500 - $117,000,000']\n",
    "\n",
    "CAT_INCOME = pd.qcut(data_lite['AMT_INCOME_TOTAL'], q = 4,\n",
    "                    labels = income_labels)\n",
    "\n",
    "CAT_INCOME.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$25,659 - $112,500</th>\n",
       "      <th>$112,500 - $147,150</th>\n",
       "      <th>$147,150 - $202,500</th>\n",
       "      <th>$202,500 - $117,000,000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.327071</td>\n",
       "      <td>0.172943</td>\n",
       "      <td>0.267350</td>\n",
       "      <td>0.232636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.469144</td>\n",
       "      <td>0.378199</td>\n",
       "      <td>0.442577</td>\n",
       "      <td>0.422513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       $25,659 - $112,500  $112,500 - $147,150  $147,150 - $202,500  \\\n",
       "count       307511.000000        307511.000000        307511.000000   \n",
       "mean             0.327071             0.172943             0.267350   \n",
       "std              0.469144             0.378199             0.442577   \n",
       "min              0.000000             0.000000             0.000000   \n",
       "25%              0.000000             0.000000             0.000000   \n",
       "50%              0.000000             0.000000             0.000000   \n",
       "75%              1.000000             0.000000             1.000000   \n",
       "max              1.000000             1.000000             1.000000   \n",
       "\n",
       "       $202,500 - $117,000,000  \n",
       "count            307511.000000  \n",
       "mean                  0.232636  \n",
       "std                   0.422513  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.000000  \n",
       "75%                   0.000000  \n",
       "max                   1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simplifying category names\n",
    "data_lite['CAT_INCOME'] = CAT_INCOME.astype('category')\n",
    "#use the get_dummies function to quickly find the percentage of the dataset that each quantile makes up\n",
    "pd.get_dummies(data_lite.CAT_INCOME).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming new dataset with target included. We will still drop features that we already decided were not useful.\n",
    "strat_inc = data_lite.copy().drop(labels = ['SK_ID_CURR','AMT_GOODS_PRICE'], axis = 1)\n",
    "#print(list(strat_inc.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train count: 246008\n",
      "y_test count: 61503\n",
      "Total: 307511\n"
     ]
    }
   ],
   "source": [
    "# stratify the training and test sets by the target first\n",
    "# must keep TARGET in the training sets at this point to under sample by income\n",
    "y = strat_inc.TARGET\n",
    "X = strat_inc\n",
    "# setting random_state\n",
    "random_state = 1\n",
    "\n",
    "X_train_strat, X_test, y_train_strat, y_test = train_test_split(X, y, test_size = .2, random_state = random_state, stratify = y)\n",
    "print('y_train count: ' + str(y_train_strat.count()) + '\\ny_test count: ' + str(y_test.count()) +\n",
    "      '\\nTotal: ' + str(y_train_strat.count() + y_test.count()))\n",
    "# removing CAT_INCOME from X_test because it was created only for stratification\n",
    "X_test = X_test.drop(labels = ['CAT_INCOME'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Income Strata**\n",
    "\n",
    "We will now take the training set and under-sample all the income categories except the majority category so that it is represented better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of training set:  (208191, 327) Size of label set:  (208191,)\n"
     ]
    }
   ],
   "source": [
    "# We are deciding to under sample all strata except the majority class\n",
    "rus = RandomUnderSampler(random_state = random_state,\n",
    "                         sampling_strategy = 'not majority')\n",
    "\n",
    "# we are undersampling based on strata defined by the CAT_INCOME variable\n",
    "y_inc = X_train_strat.CAT_INCOME\n",
    "X_rus, y_rus = rus.fit_resample(X_train_strat.drop(labels = ['CAT_INCOME'], axis = 1),y_inc)\n",
    "\n",
    "print('New size of training set: ', X_rus.shape,\n",
    "      'Size of label set: ', y_rus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have applied an under-sampling strategy to make the majority income class more easily seperable, we can now under-sample by the `TARGET` feature to further clarify the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the X_rus training data, which is randomly under-sampled by income and under-sample it once more according to the TomekLinks to make the boundary between the classes more evident. Before we can use the Tomek Link undersampling method, we must deal with NaN and None type values. We choose to impute these values based on the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus_imputed = X_rus.where(pd.notna(X_rus), X_rus.mean(), axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Verifying that no NaN values exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDIT_CNT_INSTALMENT_MATURE_CUM</th>\n",
       "      <th>CREDIT_SK_DPD</th>\n",
       "      <th>CREDIT_SK_DPD_DEF</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Active</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Approved</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Completed</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Demand</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Refused</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Sent proposal</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Signed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>2.081910e+05</td>\n",
       "      <td>2.081910e+05</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>2.081910e+05</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>2.081910e+05</td>\n",
       "      <td>208191.000000</td>\n",
       "      <td>208191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.081123</td>\n",
       "      <td>0.097559</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>0.327099</td>\n",
       "      <td>0.693022</td>\n",
       "      <td>1.593296e+05</td>\n",
       "      <td>5.775568e+05</td>\n",
       "      <td>26229.417969</td>\n",
       "      <td>5.223809</td>\n",
       "      <td>4.701889</td>\n",
       "      <td>...</td>\n",
       "      <td>2.825006</td>\n",
       "      <td>1.187625</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>0.267709</td>\n",
       "      <td>2.072705e-07</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>6.993914e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.273024</td>\n",
       "      <td>0.296719</td>\n",
       "      <td>0.468878</td>\n",
       "      <td>0.469155</td>\n",
       "      <td>0.461241</td>\n",
       "      <td>2.783113e+05</td>\n",
       "      <td>3.939565e+05</td>\n",
       "      <td>14172.670898</td>\n",
       "      <td>1.771066</td>\n",
       "      <td>2.523665</td>\n",
       "      <td>...</td>\n",
       "      <td>8.474524</td>\n",
       "      <td>23.710979</td>\n",
       "      <td>4.155921</td>\n",
       "      <td>0.436248</td>\n",
       "      <td>4.730092e-05</td>\n",
       "      <td>0.054507</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>9.236226e-05</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>1615.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035000e+05</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>16011.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.350000e+05</td>\n",
       "      <td>4.950000e+05</td>\n",
       "      <td>23994.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.890000e+05</td>\n",
       "      <td>7.871310e+05</td>\n",
       "      <td>33192.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.897461</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>258025.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.062500</td>\n",
       "      <td>1342.000000</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.123810e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860352</td>\n",
       "      <td>1.388550e-02</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              TARGET  NAME_CONTRACT_TYPE    CODE_GENDER   FLAG_OWN_CAR  \\\n",
       "count  208191.000000       208191.000000  208191.000000  208191.000000   \n",
       "mean        0.081123            0.097559       0.673651       0.327099   \n",
       "std         0.273024            0.296719       0.468878       0.469155   \n",
       "min         0.000000            0.000000       0.000000       0.000000   \n",
       "25%         0.000000            0.000000       0.000000       0.000000   \n",
       "50%         0.000000            0.000000       1.000000       0.000000   \n",
       "75%         0.000000            0.000000       1.000000       1.000000   \n",
       "max         1.000000            1.000000       1.000000       1.000000   \n",
       "\n",
       "       FLAG_OWN_REALTY  AMT_INCOME_TOTAL    AMT_CREDIT    AMT_ANNUITY  \\\n",
       "count    208191.000000      2.081910e+05  2.081910e+05  208191.000000   \n",
       "mean          0.693022      1.593296e+05  5.775568e+05   26229.417969   \n",
       "std           0.461241      2.783113e+05  3.939565e+05   14172.670898   \n",
       "min           0.000000      2.565000e+04  4.500000e+04    1615.500000   \n",
       "25%           0.000000      1.035000e+05  2.700000e+05   16011.000000   \n",
       "50%           1.000000      1.350000e+05  4.950000e+05   23994.000000   \n",
       "75%           1.000000      1.890000e+05  7.871310e+05   33192.000000   \n",
       "max           1.000000      1.170000e+08  4.050000e+06  258025.500000   \n",
       "\n",
       "       NAME_TYPE_SUITE  NAME_INCOME_TYPE  ...  \\\n",
       "count    208191.000000     208191.000000  ...   \n",
       "mean          5.223809          4.701889  ...   \n",
       "std           1.771066          2.523665  ...   \n",
       "min           0.000000          0.000000  ...   \n",
       "25%           6.000000          3.000000  ...   \n",
       "50%           6.000000          7.000000  ...   \n",
       "75%           6.000000          7.000000  ...   \n",
       "max           6.000000          7.000000  ...   \n",
       "\n",
       "       CREDIT_CNT_INSTALMENT_MATURE_CUM  CREDIT_SK_DPD  CREDIT_SK_DPD_DEF  \\\n",
       "count                     208191.000000  208191.000000      208191.000000   \n",
       "mean                           2.825006       1.187625           0.027004   \n",
       "std                            8.474524      23.710979           4.155921   \n",
       "min                            0.000000       0.000000           0.000000   \n",
       "25%                            0.000000       0.000000           0.000000   \n",
       "50%                            0.000000       0.000000           0.000000   \n",
       "75%                            0.000000       0.000000           0.000000   \n",
       "max                           73.062500    1342.000000        1277.000000   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Active  \\\n",
       "count                       208191.000000   \n",
       "mean                             0.267709   \n",
       "std                              0.436248   \n",
       "min                              0.000000   \n",
       "25%                              0.000000   \n",
       "50%                              0.000000   \n",
       "75%                              0.897461   \n",
       "max                              1.000000   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Approved  \\\n",
       "count                          2.081910e+05   \n",
       "mean                           2.072705e-07   \n",
       "std                            4.730092e-05   \n",
       "min                            0.000000e+00   \n",
       "25%                            0.000000e+00   \n",
       "50%                            0.000000e+00   \n",
       "75%                            0.000000e+00   \n",
       "max                            1.123810e-02   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Completed  \\\n",
       "count                          208191.000000   \n",
       "mean                                0.008019   \n",
       "std                                 0.054507   \n",
       "min                                 0.000000   \n",
       "25%                                 0.000000   \n",
       "50%                                 0.000000   \n",
       "75%                                 0.000000   \n",
       "max                                 1.000000   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Demand  \\\n",
       "count                       208191.000000   \n",
       "mean                             0.000022   \n",
       "std                              0.003932   \n",
       "min                              0.000000   \n",
       "25%                              0.000000   \n",
       "50%                              0.000000   \n",
       "75%                              0.000000   \n",
       "max                              0.860352   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Refused  \\\n",
       "count                         2.081910e+05   \n",
       "mean                          6.993914e-07   \n",
       "std                           9.236226e-05   \n",
       "min                           0.000000e+00   \n",
       "25%                           0.000000e+00   \n",
       "50%                           0.000000e+00   \n",
       "75%                           0.000000e+00   \n",
       "max                           1.388550e-02   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Sent proposal  \\\n",
       "count                              208191.000000   \n",
       "mean                                    0.000019   \n",
       "std                                     0.000476   \n",
       "min                                     0.000000   \n",
       "25%                                     0.000000   \n",
       "50%                                     0.000000   \n",
       "75%                                     0.000000   \n",
       "max                                     0.024384   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Signed  \n",
       "count                       208191.000000  \n",
       "mean                             0.001047  \n",
       "std                              0.017391  \n",
       "min                              0.000000  \n",
       "25%                              0.000000  \n",
       "50%                              0.000000  \n",
       "75%                              0.000000  \n",
       "max                              1.000000  \n",
       "\n",
       "[8 rows x 327 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rus_imputed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the Tomek Link Undersampling method to make the decision boundary between defaults and non-defaults more evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (201533, 326) \n",
      "Number of labels:  (201533,)\n"
     ]
    }
   ],
   "source": [
    "tl = TomekLinks()\n",
    "# now we can drop the TARGET variable from the training set and use the Tomek Links to selectively undersample the majority and clarify class boundaries.\n",
    "y = X_rus.TARGET.copy()\n",
    "X_tl, y_tl = tl.fit_sample(X_rus_imputed.drop(labels = ['TARGET'], axis = 1), y)\n",
    "print('Training set shape: ', X_tl.shape,\n",
    "      '\\nNumber of labels: ', y_tl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Downsampling to achieve balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our metric of choice is recall, which can be improved most effectively by balancing the training set. We have used two strategies that selectively under-sample the data, but an imbalance between the number of defaulted loans and non-defaulted loans still persists. We will create a final training set that has defaults and non-defaulted loans represented equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDIT_SK_DPD</th>\n",
       "      <th>CREDIT_SK_DPD_DEF</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Active</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Approved</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Completed</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Demand</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Refused</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Sent proposal</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Signed</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>2.015330e+05</td>\n",
       "      <td>201533.000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>2.015330e+05</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>2.015330e+05</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "      <td>201533.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.097557</td>\n",
       "      <td>0.673215</td>\n",
       "      <td>0.327703</td>\n",
       "      <td>0.693226</td>\n",
       "      <td>1.596837e+05</td>\n",
       "      <td>578478.625</td>\n",
       "      <td>26263.812500</td>\n",
       "      <td>5.224494</td>\n",
       "      <td>4.700451</td>\n",
       "      <td>3.225779</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217634</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.268191</td>\n",
       "      <td>2.141181e-07</td>\n",
       "      <td>0.008128</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>7.224970e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.083803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.296716</td>\n",
       "      <td>0.469039</td>\n",
       "      <td>0.469377</td>\n",
       "      <td>0.461156</td>\n",
       "      <td>2.825857e+05</td>\n",
       "      <td>395218.500</td>\n",
       "      <td>14223.931641</td>\n",
       "      <td>1.770264</td>\n",
       "      <td>2.523971</td>\n",
       "      <td>1.277960</td>\n",
       "      <td>...</td>\n",
       "      <td>24.033293</td>\n",
       "      <td>4.223977</td>\n",
       "      <td>0.436340</td>\n",
       "      <td>4.807588e-05</td>\n",
       "      <td>0.054934</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>9.387537e-05</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>0.277092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>45000.000</td>\n",
       "      <td>1615.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035000e+05</td>\n",
       "      <td>270000.000</td>\n",
       "      <td>16011.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.350000e+05</td>\n",
       "      <td>495000.000</td>\n",
       "      <td>24030.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.935000e+05</td>\n",
       "      <td>787131.000</td>\n",
       "      <td>33264.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4050000.000</td>\n",
       "      <td>258025.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1342.000000</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.123810e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860352</td>\n",
       "      <td>1.388550e-02</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME_CONTRACT_TYPE    CODE_GENDER   FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "count       201533.000000  201533.000000  201533.000000    201533.000000   \n",
       "mean             0.097557       0.673215       0.327703         0.693226   \n",
       "std              0.296716       0.469039       0.469377         0.461156   \n",
       "min              0.000000       0.000000       0.000000         0.000000   \n",
       "25%              0.000000       0.000000       0.000000         0.000000   \n",
       "50%              0.000000       1.000000       0.000000         1.000000   \n",
       "75%              0.000000       1.000000       1.000000         1.000000   \n",
       "max              1.000000       1.000000       1.000000         1.000000   \n",
       "\n",
       "       AMT_INCOME_TOTAL   AMT_CREDIT    AMT_ANNUITY  NAME_TYPE_SUITE  \\\n",
       "count      2.015330e+05   201533.000  201533.000000    201533.000000   \n",
       "mean       1.596837e+05   578478.625   26263.812500         5.224494   \n",
       "std        2.825857e+05   395218.500   14223.931641         1.770264   \n",
       "min        2.565000e+04    45000.000    1615.500000         0.000000   \n",
       "25%        1.035000e+05   270000.000   16011.000000         6.000000   \n",
       "50%        1.350000e+05   495000.000   24030.000000         6.000000   \n",
       "75%        1.935000e+05   787131.000   33264.000000         6.000000   \n",
       "max        1.170000e+08  4050000.000  258025.500000         6.000000   \n",
       "\n",
       "       NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  ...  CREDIT_SK_DPD  \\\n",
       "count     201533.000000        201533.000000  ...  201533.000000   \n",
       "mean           4.700451             3.225779  ...       1.217634   \n",
       "std            2.523971             1.277960  ...      24.033293   \n",
       "min            0.000000             0.000000  ...       0.000000   \n",
       "25%            3.000000             2.000000  ...       0.000000   \n",
       "50%            7.000000             4.000000  ...       0.000000   \n",
       "75%            7.000000             4.000000  ...       0.000000   \n",
       "max            7.000000             4.000000  ...    1342.000000   \n",
       "\n",
       "       CREDIT_SK_DPD_DEF  CREDIT_NAME_CONTRACT_STATUS_Active  \\\n",
       "count      201533.000000                       201533.000000   \n",
       "mean            0.027639                            0.268191   \n",
       "std             4.223977                            0.436340   \n",
       "min             0.000000                            0.000000   \n",
       "25%             0.000000                            0.000000   \n",
       "50%             0.000000                            0.000000   \n",
       "75%             0.000000                            0.899902   \n",
       "max          1277.000000                            1.000000   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Approved  \\\n",
       "count                          2.015330e+05   \n",
       "mean                           2.141181e-07   \n",
       "std                            4.807588e-05   \n",
       "min                            0.000000e+00   \n",
       "25%                            0.000000e+00   \n",
       "50%                            0.000000e+00   \n",
       "75%                            0.000000e+00   \n",
       "max                            1.123810e-02   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Completed  \\\n",
       "count                          201533.000000   \n",
       "mean                                0.008128   \n",
       "std                                 0.054934   \n",
       "min                                 0.000000   \n",
       "25%                                 0.000000   \n",
       "50%                                 0.000000   \n",
       "75%                                 0.000000   \n",
       "max                                 1.000000   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Demand  \\\n",
       "count                       201533.000000   \n",
       "mean                             0.000023   \n",
       "std                              0.003996   \n",
       "min                              0.000000   \n",
       "25%                              0.000000   \n",
       "50%                              0.000000   \n",
       "75%                              0.000000   \n",
       "max                              0.860352   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Refused  \\\n",
       "count                         2.015330e+05   \n",
       "mean                          7.224970e-07   \n",
       "std                           9.387537e-05   \n",
       "min                           0.000000e+00   \n",
       "25%                           0.000000e+00   \n",
       "50%                           0.000000e+00   \n",
       "75%                           0.000000e+00   \n",
       "max                           1.388550e-02   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Sent proposal  \\\n",
       "count                              201533.000000   \n",
       "mean                                    0.000019   \n",
       "std                                     0.000475   \n",
       "min                                     0.000000   \n",
       "25%                                     0.000000   \n",
       "50%                                     0.000000   \n",
       "75%                                     0.000000   \n",
       "max                                     0.024384   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Signed         TARGET  \n",
       "count                       201533.000000  201533.000000  \n",
       "mean                             0.001047       0.083803  \n",
       "std                              0.017494       0.277092  \n",
       "min                              0.000000       0.000000  \n",
       "25%                              0.000000       0.000000  \n",
       "50%                              0.000000       0.000000  \n",
       "75%                              0.000000       0.000000  \n",
       "max                              1.000000       1.000000  \n",
       "\n",
       "[8 rows x 327 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_tl.copy()\n",
    "y = y_tl.copy()\n",
    "y = y.to_frame(name = 'TARGET')\n",
    "df = pd.concat([X,y], axis = 1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDIT_SK_DPD</th>\n",
       "      <th>CREDIT_SK_DPD_DEF</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Active</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Approved</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Completed</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Demand</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Refused</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Sent proposal</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Signed</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>7875.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>327024.0</td>\n",
       "      <td>16033.5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>755190.0</td>\n",
       "      <td>36459.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>781695.0</td>\n",
       "      <td>25344.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "10                   1            1             0                1   \n",
       "16                   1            1             0                1   \n",
       "32                   0            0             1                1   \n",
       "36                   0            1             0                0   \n",
       "40                   0            1             0                1   \n",
       "\n",
       "    AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  NAME_TYPE_SUITE  \\\n",
       "10          135000.0    157500.0       7875.0                6   \n",
       "16          135000.0    225000.0      11250.0                6   \n",
       "32          135000.0    327024.0      16033.5                5   \n",
       "36          135000.0    755190.0      36459.0                6   \n",
       "40          126000.0    781695.0      25344.0                6   \n",
       "\n",
       "    NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  ...  CREDIT_SK_DPD  \\\n",
       "10                 4                    4  ...            0.0   \n",
       "16                 7                    4  ...            0.0   \n",
       "32                 7                    4  ...            0.0   \n",
       "36                 7                    4  ...            0.0   \n",
       "40                 1                    4  ...            0.0   \n",
       "\n",
       "    CREDIT_SK_DPD_DEF  CREDIT_NAME_CONTRACT_STATUS_Active  \\\n",
       "10                0.0                                 0.0   \n",
       "16                0.0                                 0.0   \n",
       "32                0.0                                 0.0   \n",
       "36                0.0                                 1.0   \n",
       "40                0.0                                 0.0   \n",
       "\n",
       "    CREDIT_NAME_CONTRACT_STATUS_Approved  \\\n",
       "10                                   0.0   \n",
       "16                                   0.0   \n",
       "32                                   0.0   \n",
       "36                                   0.0   \n",
       "40                                   0.0   \n",
       "\n",
       "    CREDIT_NAME_CONTRACT_STATUS_Completed  CREDIT_NAME_CONTRACT_STATUS_Demand  \\\n",
       "10                                    0.0                                 0.0   \n",
       "16                                    0.0                                 0.0   \n",
       "32                                    0.0                                 0.0   \n",
       "36                                    0.0                                 0.0   \n",
       "40                                    0.0                                 0.0   \n",
       "\n",
       "    CREDIT_NAME_CONTRACT_STATUS_Refused  \\\n",
       "10                                  0.0   \n",
       "16                                  0.0   \n",
       "32                                  0.0   \n",
       "36                                  0.0   \n",
       "40                                  0.0   \n",
       "\n",
       "    CREDIT_NAME_CONTRACT_STATUS_Sent proposal  \\\n",
       "10                                        0.0   \n",
       "16                                        0.0   \n",
       "32                                        0.0   \n",
       "36                                        0.0   \n",
       "40                                        0.0   \n",
       "\n",
       "    CREDIT_NAME_CONTRACT_STATUS_Signed  TARGET  \n",
       "10                                 0.0       1  \n",
       "16                                 0.0       1  \n",
       "32                                 0.0       1  \n",
       "36                                 0.0       1  \n",
       "40                                 0.0       1  \n",
       "\n",
       "[5 rows x 327 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.set_index('TARGET', inplace= True)\n",
    "defaults = df.query('TARGET == 1')\n",
    "defaults[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data shape:  (33778, 327) Percent defaults:  0.5\n"
     ]
    }
   ],
   "source": [
    "def downsampling_strategy(X, y):\n",
    "    y.columns = ['TARGET']\n",
    "    X = X.copy(deep=True)\n",
    "    y = y.copy(deep=True)\n",
    "    y = y.to_frame(name = 'TARGET')\n",
    "    random_state = 1\n",
    "    # balancing the training set\n",
    "    df = pd.concat([X, y], axis =1)\n",
    "    defaults = df[df['TARGET'] == 1]\n",
    "    nominal = df[df['TARGET'] == 0].sample(\n",
    "        n = np.round(0.5 * (defaults.TARGET.size / 0.5)).astype(int), random_state = random_state)\n",
    "    # join dataframes and shuffle\n",
    "    df = pd.concat([defaults, nominal]).sample(frac = 1, random_state = random_state)\n",
    "    \n",
    "    return df\n",
    "data_final = downsampling_strategy(X_tl, y_tl)\n",
    "print('Final Data shape: ', data_final.shape,\n",
    "     'Percent defaults: ', data_final[data_final['TARGET'] == 1].shape[0] / data_final.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDIT_SK_DPD</th>\n",
       "      <th>CREDIT_SK_DPD_DEF</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Active</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Approved</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Completed</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Demand</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Refused</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Sent proposal</th>\n",
       "      <th>CREDIT_NAME_CONTRACT_STATUS_Signed</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>3.377800e+04</td>\n",
       "      <td>3.377800e+04</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.0</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>3.377800e+04</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "      <td>33778.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.083842</td>\n",
       "      <td>0.633045</td>\n",
       "      <td>0.317337</td>\n",
       "      <td>0.685653</td>\n",
       "      <td>1.586248e+05</td>\n",
       "      <td>5.605172e+05</td>\n",
       "      <td>26016.193359</td>\n",
       "      <td>5.247350</td>\n",
       "      <td>4.888093</td>\n",
       "      <td>3.329060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150045</td>\n",
       "      <td>0.048823</td>\n",
       "      <td>0.279654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>6.615696e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.277154</td>\n",
       "      <td>0.481981</td>\n",
       "      <td>0.465447</td>\n",
       "      <td>0.464262</td>\n",
       "      <td>6.423288e+05</td>\n",
       "      <td>3.691734e+05</td>\n",
       "      <td>13326.582031</td>\n",
       "      <td>1.745836</td>\n",
       "      <td>2.527236</td>\n",
       "      <td>1.211645</td>\n",
       "      <td>...</td>\n",
       "      <td>24.191065</td>\n",
       "      <td>6.951905</td>\n",
       "      <td>0.442767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051447</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>8.598443e-05</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035000e+05</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>16456.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.350000e+05</td>\n",
       "      <td>4.856400e+05</td>\n",
       "      <td>24261.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000e+05</td>\n",
       "      <td>7.551900e+05</td>\n",
       "      <td>32602.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>230161.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.136017e-02</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME_CONTRACT_TYPE   CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "count        33778.000000  33778.000000  33778.000000     33778.000000   \n",
       "mean             0.083842      0.633045      0.317337         0.685653   \n",
       "std              0.277154      0.481981      0.465447         0.464262   \n",
       "min              0.000000      0.000000      0.000000         0.000000   \n",
       "25%              0.000000      0.000000      0.000000         0.000000   \n",
       "50%              0.000000      1.000000      0.000000         1.000000   \n",
       "75%              0.000000      1.000000      1.000000         1.000000   \n",
       "max              1.000000      1.000000      1.000000         1.000000   \n",
       "\n",
       "       AMT_INCOME_TOTAL    AMT_CREDIT    AMT_ANNUITY  NAME_TYPE_SUITE  \\\n",
       "count      3.377800e+04  3.377800e+04   33778.000000     33778.000000   \n",
       "mean       1.586248e+05  5.605172e+05   26016.193359         5.247350   \n",
       "std        6.423288e+05  3.691734e+05   13326.582031         1.745836   \n",
       "min        2.565000e+04  4.500000e+04    1980.000000         0.000000   \n",
       "25%        1.035000e+05  2.700000e+05   16456.500000         6.000000   \n",
       "50%        1.350000e+05  4.856400e+05   24261.750000         6.000000   \n",
       "75%        1.800000e+05  7.551900e+05   32602.500000         6.000000   \n",
       "max        1.170000e+08  4.050000e+06  230161.500000         6.000000   \n",
       "\n",
       "       NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  ...  CREDIT_SK_DPD  \\\n",
       "count      33778.000000         33778.000000  ...   33778.000000   \n",
       "mean           4.888093             3.329060  ...       1.150045   \n",
       "std            2.527236             1.211645  ...      24.191065   \n",
       "min            1.000000             0.000000  ...       0.000000   \n",
       "25%            3.000000             4.000000  ...       0.000000   \n",
       "50%            7.000000             4.000000  ...       0.000000   \n",
       "75%            7.000000             4.000000  ...       0.000000   \n",
       "max            7.000000             4.000000  ...    1277.000000   \n",
       "\n",
       "       CREDIT_SK_DPD_DEF  CREDIT_NAME_CONTRACT_STATUS_Active  \\\n",
       "count       33778.000000                        33778.000000   \n",
       "mean            0.048823                            0.279654   \n",
       "std             6.951905                            0.442767   \n",
       "min             0.000000                            0.000000   \n",
       "25%             0.000000                            0.000000   \n",
       "50%             0.000000                            0.000000   \n",
       "75%             0.000000                            0.973511   \n",
       "max          1277.000000                            1.000000   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Approved  \\\n",
       "count                               33778.0   \n",
       "mean                                    0.0   \n",
       "std                                     0.0   \n",
       "min                                     0.0   \n",
       "25%                                     0.0   \n",
       "50%                                     0.0   \n",
       "75%                                     0.0   \n",
       "max                                     0.0   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Completed  \\\n",
       "count                           33778.000000   \n",
       "mean                                0.007350   \n",
       "std                                 0.051447   \n",
       "min                                 0.000000   \n",
       "25%                                 0.000000   \n",
       "50%                                 0.000000   \n",
       "75%                                 0.000000   \n",
       "max                                 1.000000   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Demand  \\\n",
       "count                        33778.000000   \n",
       "mean                             0.000017   \n",
       "std                              0.003063   \n",
       "min                              0.000000   \n",
       "25%                              0.000000   \n",
       "50%                              0.000000   \n",
       "75%                              0.000000   \n",
       "max                              0.562988   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Refused  \\\n",
       "count                         3.377800e+04   \n",
       "mean                          6.615696e-07   \n",
       "std                           8.598443e-05   \n",
       "min                           0.000000e+00   \n",
       "25%                           0.000000e+00   \n",
       "50%                           0.000000e+00   \n",
       "75%                           0.000000e+00   \n",
       "max                           1.136017e-02   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Sent proposal  \\\n",
       "count                               33778.000000   \n",
       "mean                                    0.000013   \n",
       "std                                     0.000394   \n",
       "min                                     0.000000   \n",
       "25%                                     0.000000   \n",
       "50%                                     0.000000   \n",
       "75%                                     0.000000   \n",
       "max                                     0.014923   \n",
       "\n",
       "       CREDIT_NAME_CONTRACT_STATUS_Signed        TARGET  \n",
       "count                        33778.000000  33778.000000  \n",
       "mean                             0.001082      0.500000  \n",
       "std                              0.018085      0.500007  \n",
       "min                              0.000000      0.000000  \n",
       "25%                              0.000000      0.000000  \n",
       "50%                              0.000000      0.500000  \n",
       "75%                              0.000000      1.000000  \n",
       "max                              1.000000      1.000000  \n",
       "\n",
       "[8 rows x 327 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Principal Component Analysis\n",
    "\n",
    "Our feature selection decisions prompted a review of the Principal Components to see if a more significant separation between the classes is evident. We dropped variables that seemed the least useful for this type of analysis. Next, we on-hot encoded to eliminate the duplication of categorical features that were already binary indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping variables that were deemed the least useful for analysis\n",
    "y_train = data_final.TARGET.copy()\n",
    "new_df = data_final.copy().drop(['TARGET'], axis = 1)\n",
    "new_df = new_df.fillna(0)\n",
    "# one-hot encoding\n",
    "# adding drop_first = True eliminates the duplication of categorical features that are already binary indicators\n",
    "#new_df = pd.get_dummies(new_df, drop_first = True)\n",
    "# filling missing values for credit_length with 0\n",
    "#new_df = new_df.fillna(0, inplace = True)\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(new_df)\n",
    "X_std = sc.transform(new_df) \n",
    "X_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the least useful variables and preforming a one-hot encoding, the resulting data set had an increase in the features from 92 to 192."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov(X_std.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "print('\\nTop Ten Eigenvalues \\n%s' % eigen_vals[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total var explained and cumulative variance\n",
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i/tot) for i in sorted(eigen_vals, reverse =True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "len(var_exp)\n",
    "len(cum_var_exp)\n",
    "print(\"Variance Explained length: \" + str(len(var_exp)), \"\\nCumulative Variance Explained length : \" + str(len(cum_var_exp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1,327), var_exp, alpha = .5, align = 'center', label = 'Individual Explained Variance')\n",
    "\n",
    "plt.step(range(1,327), cum_var_exp, where = 'mid', label = 'Cumulative Variance Explained')\n",
    "\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xlabel('Principal Componenet Index')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significant Findings**\n",
    "\n",
    "To capture at least 80% of the variability in the dataset, we must include around 125 principal components. While this is a large number of features, our previous dataset contained 302 features. Our efforts to reduce the cardinality of several features were effective. \n",
    "\n",
    "We will pair the eigenvectors with their corresponding eigenvalues and project them onto a 2-dimensional subspace and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a listof (eigenvalues, eigenvector) tuples\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:,i]) for i in range(len(eigen_vals))]\n",
    "\n",
    "#sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "\"\"\"eigen_pairs[0] is equivalent to the single eigenvalue for PC1 and the eigenvector that represents the 190 features of the data\"\"\"\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse = True)\n",
    "\n",
    "#collecting the two eigenvectors that correspond to the two largest eigenvalues\n",
    "\n",
    "W = np.hstack((eigen_pairs[0][1][:,np.newaxis],\n",
    "               eigen_pairs[1][1][:,np.newaxis]))\n",
    "\n",
    "# printing the first 5 pairs\n",
    "print('Matrix W: \\n', W[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this matrix to transform the training set into new features and plot them. First, we will observe the first 2 Principal Components with a logistic regression-based decision boundary to view the discriminatory ability of a logistic model using the Principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33778, 307511]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-a3b7af198ff6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mX_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#fitting the logitistic regression model on the reduced dataset:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Logistic Regression: Decision Boundary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1527\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33778, 307511]"
     ]
    }
   ],
   "source": [
    "#transforming data\n",
    "X_pca = X_std.dot(W)\n",
    "\n",
    "# identifying labels\n",
    "y_pca = data.TARGET\n",
    "\n",
    "#initializing the PCA transformer and logistic regression estimator:\n",
    "pca = PCA(n_components =2)\n",
    "lr = LogisticRegression(multi_class = 'ovr',\n",
    "                        random_state = 1,\n",
    "                        solver = 'lbfgs')\n",
    "# dimensionality reduction:\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "#fitting the logitistic regression model on the reduced dataset:\n",
    "lr.fit(X_pca, y_pca)\n",
    "plot_decision_regions(X_pca, y_pca, classifier = lr)\n",
    "plt.title('Logistic Regression: Decision Boundary')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend(loc = 'lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significant Findings**\n",
    "\n",
    "From this plot, we can see that class separation is very poor and non-linear. We have two centroids where each has only a slight concentric-ellipse type of separation between the two classes. The decision boundary drawn by a logistic model is clearly unable to use the first two principal components to discriminate between defaults and non-defaulted loans.\n",
    "\n",
    "\n",
    "We can also attempt to view the value of the third principal component to see if there is good separation when we add a third dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting three principal components\n",
    "W3 = np.hstack((W,eigen_pairs[2][1][:,np.newaxis]))\n",
    "W3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transforming training data\n",
    "X_pca3 = X_std.dot(W3)\n",
    "X_pca3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.6600926 +0.j, -0.10526478+0.j, -0.13417634+0.j],\n",
       "       [-0.22692169+0.j, -3.91638704+0.j,  0.09676031+0.j],\n",
       "       [-6.02746049+0.j,  0.44800945+0.j, -0.64520426+0.j],\n",
       "       [ 4.28433742+0.j, -0.58719161+0.j,  1.06701953+0.j],\n",
       "       [ 0.48885546+0.j, -2.62098338+0.j,  1.13188733+0.j],\n",
       "       [-1.17604636+0.j, -1.97421468+0.j,  0.20506668+0.j],\n",
       "       [-4.56618178+0.j, -0.43215067+0.j, -1.33208055+0.j],\n",
       "       [-4.7109809 +0.j, -1.65896707+0.j, -1.16507453+0.j],\n",
       "       [ 4.51620746+0.j, -0.46317666+0.j, -1.05006942+0.j],\n",
       "       [ 1.80855049+0.j, -1.32837513+0.j,  2.62315961+0.j]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca3[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "\n",
    "colors = ['r','g']\n",
    "markers = ['o', 'x']\n",
    "\n",
    "# for each index and class in:\n",
    "for idx, cl in enumerate(np.unique(y_pca)):\n",
    "    ax.scatter3D(X_pca3[y_pca == cl, 0],\n",
    "                X_pca3[y_pca == cl, 1],\n",
    "                X_pca3[y_pca == cl, 2],\n",
    "                label = cl,\n",
    "                s=500,\n",
    "                c = X_pca3[y_pca == cl, 2],\n",
    "                cmap = 'viridis',\n",
    "                marker = markers[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significant Findings**\n",
    "\n",
    "A three dimensional plot of the data does provide some insights. Defaults can be separated along the third dimension, as indicated by the defaults being clustered in the blue region and the non-defaults being clustered in the green/yellow regions of the third Principal Component.\n",
    "\n",
    "1. The overlap between the classes is so signficant even in the third dimension, that the boundary line is not clear.\n",
    "\n",
    "2. We will apply sampling strategies that will clarify the class boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Feature Importance Assessment\n",
    "\n",
    "An analysis of feature importance was performed by removing features with high variance inflation factor (VIF) and ranking features by absolute mean feature importance from an ensemble of models (regularized logistic regression).\n",
    "\n",
    "#### 1.1.2.1 Feature Removal By VIF\n",
    "\n",
    "High VIF is an [indication of multicollinearity](https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html).\n",
    "Typically, limiting VIF of individual features to 5 is considered reasonable.\n",
    "For removal by VIF, features with high VIF were removed iteratively until the VIF for all remain features was less than 5.\n",
    "The VIF reduction method removed 75 features, leaving 251 features.\n",
    "The full list of dropped features is shown below.\n",
    "\n",
    "```python\n",
    "transformer = ReduceVIF()\n",
    "X = transformer.fit_transform(X_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"400\"\n",
       "            src=\"./vif_features.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd5521759b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./vif_features.html\", width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.2 Feature Importance From Ensemble\n",
    "\n",
    "The training data was split into training and validation sets (80/20) split - \n",
    "the validation split is used in the performance estimation.\n",
    "Feature Importance was estimated by training a logstic model with L2 regularization and a logistic model with L1 regularization on the training set with the reduced number of features.\n",
    "Once the models were fit, the model weights were extracted and combined for each feature.\n",
    "The features were ranked by the average of the absolute value of the model weights.\n",
    "The table is shown below\n",
    "\n",
    "**Column Meanings**\n",
    "\n",
    "* `Mean_Abs_Weight`: The mean of the absolute values of the weights assigned to features by the logistic models.\n",
    "* `Feature`: The feature name.\n",
    "* `l1_Weight`: The parameter weight assigned my the logistic model with L1 regularization.\n",
    "* `l2_Weight`: The parameter weight assigned my the logistic model with L2 regularization.\n",
    "* `Importance_Difference`: The difference btween the weight assigned by the LASSO logistic model and the weight assigned by the ridge logistic regression model.\n",
    "* `Importance_Difference_%`: The percent difference between the weight assigned by the LASSO logistic model and the weight assigned by the ridge logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"400\"\n",
       "            src=\"./feature_importance.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd552175470>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./feature_importance.html\", width=1200, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Abs_Weight</th>\n",
       "      <th>Feature</th>\n",
       "      <th>l1_Weight</th>\n",
       "      <th>l2_Weight</th>\n",
       "      <th>Importance_Difference</th>\n",
       "      <th>Importance_Difference_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>DAYS_BIRTH</td>\n",
       "      <td>-3.585076e-08</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>199.695868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>DAYS_REGISTRATION</td>\n",
       "      <td>-1.665249e-08</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>199.684367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>PREV_AMT_ANNUITY</td>\n",
       "      <td>-1.638168e-08</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>199.656594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>BUREAU_DAYS_CREDIT_ENDDATE</td>\n",
       "      <td>1.511157e-08</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-199.657891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>2.160590e-08</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-199.424674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>CREDIT_AMT_DRAWINGS_ATM_CURRENT</td>\n",
       "      <td>4.453810e-08</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-198.806963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>PREV_AMT_DOWN_PAYMENT</td>\n",
       "      <td>-5.065099e-08</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>198.638295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "      <td>-1.038555e-08</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>199.715075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>DAYS_ID_PUBLISH</td>\n",
       "      <td>-8.804749e-09</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>199.714414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>INSTA_AMT_PAYMENT</td>\n",
       "      <td>-2.516650e-08</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>199.071822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_Abs_Weight                          Feature     l1_Weight  l2_Weight  \\\n",
       "0         0.000024                       DAYS_BIRTH -3.585076e-08  -0.000047   \n",
       "1         0.000011                DAYS_REGISTRATION -1.665249e-08  -0.000021   \n",
       "2         0.000010                 PREV_AMT_ANNUITY -1.638168e-08  -0.000019   \n",
       "3         0.000009       BUREAU_DAYS_CREDIT_ENDDATE  1.511157e-08   0.000018   \n",
       "4         0.000008                      AMT_ANNUITY  2.160590e-08   0.000015   \n",
       "5         0.000007  CREDIT_AMT_DRAWINGS_ATM_CURRENT  4.453810e-08   0.000015   \n",
       "6         0.000007            PREV_AMT_DOWN_PAYMENT -5.065099e-08  -0.000015   \n",
       "7         0.000007                    DAYS_EMPLOYED -1.038555e-08  -0.000015   \n",
       "8         0.000006                  DAYS_ID_PUBLISH -8.804749e-09  -0.000012   \n",
       "9         0.000005                INSTA_AMT_PAYMENT -2.516650e-08  -0.000011   \n",
       "\n",
       "   Importance_Difference  Importance_Difference_%  \n",
       "0               0.000047               199.695868  \n",
       "1               0.000021               199.684367  \n",
       "2               0.000019               199.656594  \n",
       "3              -0.000018              -199.657891  \n",
       "4              -0.000015              -199.424674  \n",
       "5              -0.000015              -198.806963  \n",
       "6               0.000015               198.638295  \n",
       "7               0.000015               199.715075  \n",
       "8               0.000012               199.714414  \n",
       "9               0.000011               199.071822  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code creates the feature importance table.\n",
    "\n",
    "# only do this analysis on the training data\n",
    "X, X_val, y, y_val = train_test_split(data_final.drop('TARGET', axis = 1), data_final.TARGET, test_size = 0.2,\n",
    "                                      random_state = random_state)\n",
    "\n",
    "\n",
    "# train logistic models\n",
    "logistic_l1 = LogisticRegression(C = 0.01,\n",
    "                                 penalty = 'l1', \n",
    "                                 solver = 'saga', \n",
    "                                 random_state = random_state)\n",
    "logistic_l1.fit(X, y)\n",
    "\n",
    "logistic_l2 = LogisticRegression(C = 0.01, \n",
    "                                 penalty = 'l2',\n",
    "                                 solver = 'lbfgs', \n",
    "                                 random_state = random_state)\n",
    "logistic_l2.fit(X, y)\n",
    "\n",
    "# extract the l1 coefficients\n",
    "coefs = logistic_l1.coef_\n",
    "pd.set_option('display.max_rows', 500)\n",
    "coefs_df = pd.DataFrame(data=coefs.flatten())\n",
    "feats_df = X.columns\n",
    "feats_df = feats_df.tolist()\n",
    "feats_df = pd.DataFrame(feats_df)\n",
    "df_new_coeffs = pd.concat([feats_df, coefs_df], axis=1).dropna()\n",
    "df_new_coeffs.columns = ['Feature', 'Logistic Weight']\n",
    "final_df_logistic_l1 = df_new_coeffs.sort_values('Logistic Weight')\n",
    "final_df_logistic_l1['Abs Weight'] = np.abs(final_df_logistic_l1['Logistic Weight'])\n",
    "final_df_logistic_l1.sort_values('Abs Weight', ascending=False, inplace = True)\n",
    "\n",
    "# extract the l2 coefficients\n",
    "coefs = logistic_l2.coef_\n",
    "pd.set_option('display.max_rows', 500)\n",
    "coefs_df = pd.DataFrame(data=coefs.flatten())\n",
    "feats_df = X.columns\n",
    "feats_df = feats_df.tolist()\n",
    "feats_df = pd.DataFrame(feats_df)\n",
    "df_new_coeffs = pd.concat([feats_df, coefs_df], axis=1).dropna()\n",
    "df_new_coeffs.columns = ['Feature', 'Logistic Weight']\n",
    "final_df_logistic_l2 = df_new_coeffs.sort_values('Logistic Weight')\n",
    "final_df_logistic_l2['Abs Weight'] = np.abs(final_df_logistic_l2['Logistic Weight'])\n",
    "final_df_logistic_l2.sort_values('Abs Weight', ascending=False, inplace = True)\n",
    "\n",
    "# prevent risk of object corruption\n",
    "l2 = final_df_logistic_l2.sort_values('Feature').copy().add_suffix('_l2')\n",
    "l1 = final_df_logistic_l1.sort_values('Feature').copy().add_suffix('_l1')\n",
    "\n",
    "# combine the feature weights, calculate mean abs, and sort\n",
    "# just print the head\n",
    "combined = pd.concat([l1, l2], keys=['Feature_l1', 'Feature_l2'], axis = 1)\n",
    "combined['Average Weight'] = (combined['Feature_l1']['Abs Weight_l1'] \n",
    "                              + combined['Feature_l2']['Abs Weight_l2']) / 2\n",
    "average_weights = pd.DataFrame()\n",
    "average_weights['Mean_Abs_Weight'] = combined['Average Weight']\n",
    "average_weights['Feature'] = combined['Feature_l1']['Feature_l1']\n",
    "average_weights['l1_Weight'] = combined['Feature_l1']['Logistic Weight_l1']\n",
    "average_weights['l2_Weight'] = combined['Feature_l2']['Logistic Weight_l2']\n",
    "average_weights['Importance_Difference'] = average_weights['l1_Weight'] - average_weights['l2_Weight']\n",
    "average_weights['Importance_Difference_%'] = (average_weights['Importance_Difference'] \n",
    "                                              / average_weights['Mean_Abs_Weight'] \n",
    "                                              * 100)\n",
    "average_weights = average_weights.sort_values('Mean_Abs_Weight', ascending = False).reset_index(drop = True)\n",
    "average_weights.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.3 Estimation of Performance Over Feature Space\n",
    "\n",
    "Once the features were ranked, the number of features needed for classification was estimated by iterative training and testing a logistic model and a hist gradient boosting model on the ranked feature set.\n",
    "On each iteration, 5 features were added to the feature space used by the model for training and testing until the maximum feature space was reached.\n",
    "The following plots show the model performance over the feature space.\n",
    "The logistic model appears to stabilize once the top 50 features were added to the model, while the HGBM appears to stablity once the top 75 features were added to the model.\n",
    "The models were tested on the 20% validation split from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold feature performance\n",
    "log_acc = list()\n",
    "log_recall = list()\n",
    "log_pre = list()\n",
    "feat_count = list()\n",
    "hgbm_acc = list()\n",
    "hgbm_recall = list()\n",
    "hgbm_pre = list()\n",
    "feat_count = list()\n",
    "\n",
    "# init models\n",
    "# models use baseline regularization\n",
    "l = LogisticRegression(C = 0.01, \n",
    "                       penalty = 'l2',\n",
    "                       solver = 'lbfgs', \n",
    "                       random_state = random_state)\n",
    "\n",
    "clf = HistGradientBoostingClassifier(l2_regularization= 0, \n",
    "                                     learning_rate= 0.1,\n",
    "                                     loss= 'binary_crossentropy',\n",
    "                                     max_iter= 100,\n",
    "                                     max_leaf_nodes= 41,\n",
    "                                     min_samples_leaf= 20,\n",
    "                                     random_state = random_state)\n",
    "\n",
    "# calculate performance over by iterative adding features\n",
    "# with a step size of 5\n",
    "for f_count in range(10, 260, 5):\n",
    "    feat_count.append(f_count)\n",
    "    \n",
    "    l.fit(X[average_weights.iloc[0:f_count].Feature], y)\n",
    "\n",
    "    # using it on test set\n",
    "    y_pred = l.predict(X_val[average_weights.iloc[0:f_count].Feature])\n",
    "    #results = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    log_acc.append(accuracy_score(y_val, y_pred))\n",
    "    log_pre.append(precision_score(y_val, y_pred))\n",
    "    log_recall.append(recall_score(y_val, y_pred))\n",
    "\n",
    "feat_count = list()\n",
    "for f_count in range(10,260,5):\n",
    "    feat_count.append(f_count)\n",
    "    \n",
    "    clf.fit(X[average_weights.iloc[0:f_count].Feature], y)\n",
    "\n",
    "    # using it on test set\n",
    "    y_pred = clf.predict(X_val[average_weights.iloc[0:f_count].Feature])\n",
    "    #results = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    hgbm_acc.append(accuracy_score(y_val, y_pred))\n",
    "    hgbm_pre.append(precision_score(y_val, y_pred))\n",
    "    hgbm_recall.append(recall_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the performance of both models\n",
    "fig, ax = plt.subplots(ncols=2, sharey = True, figsize=(15,7))\n",
    "\n",
    "ax[0].plot(feat_count, log_acc, label = 'accuracy')\n",
    "ax[0].plot(feat_count, log_pre, label = 'precision')\n",
    "ax[0].plot(feat_count, log_recall, label = 'recall')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Logistic Model Performance vs Features')\n",
    "ax[0].set_xlabel('Number of Features')\n",
    "ax[0].set_ylabel('Performance')\n",
    "#plt.ylim((0.68, 0.74))\n",
    "\n",
    "ax[1].plot(feat_count, hgbm_acc, label = 'accuracy')\n",
    "ax[1].plot(feat_count, hgbm_pre, label = 'precision')\n",
    "ax[1].plot(feat_count, hgbm_recall, label = 'recall')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('HGBM Model Performance vs Features')\n",
    "ax[1].set_xlabel('Number of Features')\n",
    "ax[1].set_ylabel('Performance')\n",
    "#plt.ylim((0.68, 0.78))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2 Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). (Q1b) <a class=\"anchor\" id=\"FinalDataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation**\n",
    "\n",
    "The function `impute_data` calculates imputations values for the following values and applies these values to test set.\n",
    "For categorical variables imputation of the mode was used.\n",
    "For continuous variables imputation of the median was used.\n",
    "\n",
    "| Variable | Imputation Method |\n",
    "|----------|-------------------|\n",
    "| CODE_GENDER | Mode |\n",
    "| NAME_TYPE_SUITE | Mode |\n",
    "| OBS_30_CNT_SOCIAL_CIRCLE | Median |\n",
    "| DEF_30_CNT_SOCIAL_CIRCLE | Median |\n",
    "| OBS_60_CNT_SOCIAL_CIRCLE | Median |\n",
    "| DEF_60_CNT_SOCIAL_CIRCLE | Median |\n",
    "| AMT_ANNUITY |  Median |\n",
    "| ANNUITY_INCOME_RATIO |  Median |\n",
    "| DAYS_LAST_PHONE_CHANGE |  Median |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the imputated test and train for analysis of the SVM\n",
    "data_imputed = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Describe the final dataset that is used for classification/regression (Q1B)<a class=\"anchor\" id=\"FinalDataset\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Stage Four - Modeling and Evaluation (Q2) <a class=\"DataUnderstanding\" id=\"EDA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Choose and explain your evaluation metrics (Q2A) <a class=\"anchor\" id=\"Evaluaation\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the significant overlap between the classes in our dataset, we have elected to evaluate our models using the recall metric. Recall is the ratio of accurately predicted defaults to total defaults, which allows us to extract value from the model. \n",
    "\n",
    "We will provide an example of why we deemed this necessary.\n",
    "\n",
    "Below is a Gradient Boosting Machines model that uses the entire dataset to make class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # enabling sklearn's experimental gradient boosting machine algorithm\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    " # now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf = HistGradientBoostingClassifier().fit(X_train_std, y_train)\n",
    "clf.score(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 92% is deceptive. The significant imbalance of the dataset creates this deception. The goal of the analysis is to build a model capable of predicting loan defaults. If we remember that over 90% of the loans in the dataset were in good standing, we can then understand how our model can easily achieve an accuracy of at least 90% by sheer coincidence. \n",
    "\n",
    "We will now observe the recall of the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf, X_train_std, y_train, cv = 5, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall ability of this model ranges from 1.1% to 1.3%. This reveals that the model is useless for predicting loan defaults. \n",
    "\n",
    "We will experiment with various resampling strategies until significant improvements are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Choose the method you will use for dividing your data (Q2B) <a class=\"anchor\" id=\"Describedata\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using an 80/20 training : test set split.\n",
    "\n",
    "As previously mentioned in section 1.2 (Data Description) we concluded that it was necessary to implement a sampling strategy on the training set in order to make a useful model for predicting loan defaults. \n",
    "\n",
    "As a justification of the use of a generic sampling strategy with this dataset, we will provide an example of the effectiveness of simple Randum Under Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X = X_train_std\n",
    "y = data.TARGET\n",
    "rus = RandomUnderSampler(random_state = 1)\n",
    "X_rus, y_rus = rus.fit_resample(X,y)\n",
    "y_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HistGradientBoostingClassifier().fit(X_rus, y_rus)\n",
    "clf.score(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X_rus, y_rus, cv = 5, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying random under-sampling of the majority class permits the gradient boosting algorithm to better define the class differences. Our ability to detect loans that enter default status increased over 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3  Create three different classification/regression models (Q2C) <a class=\"anchor\" id=\"Models\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Analyze the results using your chosen method of evaluation (Q2D) <a class=\"anchor\" id=\"Analyze\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Discuss the advantages of each model for each classification task (Q2E) <a class=\"anchor\" id=\"Advantages\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Which attributes from your analysis are most important (Q2F) <a class=\"anchor\" id=\"Attributes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stage Five - Deployment (Q3) <a class=\"anchor\" id=\"Deployment\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? (Q3A) <a class=\"anchor\" id=\"Value\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1. Disclaimer<a class=\"anchor\" id=\"Disclaimer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer for Home Credit Default Research Paper\n",
    "If you require any more information or have any questions about this papers disclaimer, please feel free to contact us by email at mschwan@smu.edu\n",
    "## Disclaimers for Home Credit Default Research Paper\n",
    "All the information for this research paper is published in good faith and for general information purpose only. Spring 2020 SMU Machine Learning One project team Schwan, Adams, Stewart, and Howard does not make any warranties about the completeness, reliability, and accuracy of this information. Any action you take upon the information you find within this paper is strictly at your own risk. This project team will not be liable for any losses and/or damages in connection with the use of our research analysis paper.\n",
    "From our references, you can visit other websites and papers by following hyperlinks to such external sites. While we strive to provide only quality research references to useful and ethical content, we have no control over the content and nature of these sites. These links to other websites and papers do not imply a recommendation for all the content found within. Please be also aware that when you leave our website, other sites may have different privacy policies and terms which are beyond our control. Please be sure to check the Privacy Policies of these sites as well as their “Terms of Service” before engaging in any business or uploading any information.\n",
    "## Consent\n",
    "By reading our research paper content, you hereby consent to our disclaimer and agree to its terms.\n",
    "## Update\n",
    "Should we update, amend or make any changes to this document, those changes will be prominently posted here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
